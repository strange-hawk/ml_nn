{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOKt4JsmnILovmFWKUvuSW5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/strange-hawk/ml_nn/blob/master/nn_prac.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmD6oJ2QTCmC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vw3nFyPprIAL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rides = pd.read_csv('https://raw.githubusercontent.com/udacity/deep-learning/master/first-neural-network/Bike-Sharing-Dataset/hour.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-X6VFW5lIoRB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dummy_values=['season','weekday','mnth','weathersit','hr']\n",
        "for d in dummy_values:\n",
        "  rides = pd.concat([rides,pd.get_dummies(rides[d],prefix=d)],axis=1)\n",
        "  rides.drop(d,axis=1,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QotkuArNIoYT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rides.drop(['instant','dteday','atemp','workingday'],axis=1,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLCPMLZ0Nji5",
        "colab_type": "text"
      },
      "source": [
        "**scaling**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDmax-GuIowM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in ['temp','casual','hum','registered','cnt']:\n",
        "  mean,std = rides[i].mean(),rides[i].std()\n",
        "  rides[i] = (rides[i]-mean)/std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M07SMCX7IoqQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data=rides[-21*24:]\n",
        "train = rides[:-21*24]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqDFHI78Ioo4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_fields= ['cnt','registered','casual']\n",
        "targets = rides[target_fields]\n",
        "features = rides.drop(target_fields,axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xP2OnXn9IonO",
        "colab_type": "code",
        "outputId": "cf39c704-94e6-4497-8e4a-d638196f195e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "features.shape , targets.shape"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((17379, 56), (17379, 3))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3euJwfEddwJi",
        "colab_type": "text"
      },
      "source": [
        "**splitting the data into train,vaidate dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXwRTWRTIojr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_records =  features.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z72Aso6dIofz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "split = np.random.choice(a=features.index ,size=int(n_records*0.8), replace=False )\n",
        "train_features,train_targets = features.iloc[split],targets.iloc[split]\n",
        "validate_features,vaidate_targets = features.drop(split),targets.drop(split)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8snuX0tUIoa-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mse(y,Y):\n",
        "  return np.mean((y-Y)**2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6uhozXTIoW0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoidFunction(x):\n",
        "  return 1/(1+np.exp(-x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ET6m4UctPGj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NeuralNetwork:\n",
        "  def __init__(self,input_nodes,hidden_nodes,output_nodes,learning_rate ):\n",
        "    self.input_nodes = input_nodes\n",
        "    self.hidden_nodes = hidden_nodes\n",
        "    self.output_nodes = output_nodes\n",
        "    self.learning_rate = learning_rate\n",
        "    self.weights_input_hidden = np.random.normal(loc=0.0, scale=self.hidden_nodes**-0.5,size= (self.input_nodes, self.hidden_nodes))\n",
        "    self.weights_hidden_output = np.random.normal(loc=0.0, scale=self.output_nodes**-0.5,size= (self.hidden_nodes,self.output_nodes))\n",
        "    self.learning_rate = learning_rate\n",
        "    print(self.weights_input_hidden.shape,self.weights_hidden_output.shape)\n",
        "    self.activation_function = sigmoidFunction\n",
        "  \n",
        "  def train(self,features,target):\n",
        "    n_records=features.shape[0]\n",
        "    delta_w_i_h = np.zeros(self.weights_input_hidden.shape)\n",
        "    delta_w_h_o = np.zeros(self.weights_hidden_output.shape)\n",
        "    for x,y in zip(features,target):\n",
        "      hidden_input = np.dot(x,self.weights_input_hidden)\n",
        "      hidden_output = self.activation_function(hidden_input)\n",
        "      output_in = np.dot(hidden_output,self.weights_hidden_output)\n",
        "      final_output = self.activation_function(output_in)\n",
        "      # backpropagation\n",
        "      error = y - final_output\n",
        "      output_error_term = error*final_output*(1-final_output)\n",
        "      hidden_error= np.dot(output_error_term,self.weights_hidden_output.T)\n",
        "      hidden_error_term = hidden_error*hidden_output*(1.-hidden_output)\n",
        "      # delta_w_i_h +=  np.outer(x,hidden_error_term)\n",
        "      delta_w_h_o += np.outer(hidden_output,output_error_term)\n",
        "      delta_w_i_h +=  np.outer(x,hidden_error_term)\n",
        "\n",
        "    # weight updation\n",
        "    self.weights_hidden_output += self.learning_rate*delta_w_h_o/n_records\n",
        "    self.weights_input_hidden += self.learning_rate*delta_w_i_h/n_records\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def run(self,features):\n",
        "    hidden_inputs = np.dot(features,self.weights_input_hidden)\n",
        "    hidden_outputs = self.activation_function(hidden_inputs)\n",
        "    final_inputs = np.dot(hidden_outputs,self.weights_hidden_output)\n",
        "    final_output = self.activation_function(final_inputs)\n",
        "\n",
        "    return final_output\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2-Ipl_aIoV5",
        "colab_type": "code",
        "outputId": "71e63b43-05d1-47ea-9baa-9ac79014b570",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "epochs = 3000\n",
        "learning_rate=0.01\n",
        "hidden_nodes = 10\n",
        "output_nodes = 1\n",
        "N_i = train_features.shape[1]\n",
        "# print(train_features.index)\n",
        "network = NeuralNetwork(N_i,hidden_nodes,output_nodes,learning_rate)\n",
        "losses={'train':[], 'validation':[]}\n",
        "batch = np.random.choice(train_features.shape[0],size=128,replace=False)\n",
        "for i in range(epochs):\n",
        "  record,target = train_features.iloc[batch].values,train_targets.iloc[batch]['cnt']\n",
        "  network.train(record,target)\n",
        "  if e%(epochs/10) ==0:\n",
        "    train_loss = mse(network.run(train_features),train_targets['cnt'].values)\n",
        "    validation_loss = mse(network.run(validate_features),vaidate_targets['cnt'].values)\n",
        "    losses['train'].append(train_loss)\n",
        "    losses['validation'].append(validation_loss)\n",
        "    print('Training loss: {:.4f}'.format(train_loss))\n",
        "    print('Validation loss: {:.4f}'.format(validation_loss))\n",
        "#   network.train(record,target)\n",
        "# record,target = zip(train_features.iloc[0].values,train_targets.iloc[0]['cnt'])\n",
        "# print(type(record),target)\n",
        "\n",
        "# for e in range(epochs):\n",
        "#   batch = np.random.choice(train_features.shape[0],size=128,replace=False)\n",
        "#   for record,target in zip(train_features.iloc[batch].values,train_targets.iloc[batch]['cnt']):\n",
        "#     print(record.shape,target.shape)\n",
        "#     network.train(record,train)\n",
        "#   if e%(epochs/10) ==0:\n",
        "#     train_loss = mse(network.run(train_features),train_targets['cnt'].values)\n",
        "#     validation_loss = mse(network,run(validate_features),validate_targets['cnt'].values)\n",
        "#     losses['train'].append(train_loss)\n",
        "#     losses['validation'].apend(validation_loss)\n",
        "#     print('Training loss: {:.4f}'.format(train_loss))\n",
        "#     print('Validation loss: {:.4f}'.format(validation_loss))\n"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Validation loss: 1.0224\n",
            "Training loss: 1.0124\n",
            "Validation loss: 1.0224\n",
            "Training loss: 1.0124\n",
            "Validation loss: 1.0224\n",
            "Training loss: 1.0124\n",
            "Validation loss: 1.0224\n",
            "Training loss: 1.0124\n",
            "Validation loss: 1.0223\n",
            "Training loss: 1.0123\n",
            "Validation loss: 1.0223\n",
            "Training loss: 1.0123\n",
            "Validation loss: 1.0223\n",
            "Training loss: 1.0123\n",
            "Validation loss: 1.0223\n",
            "Training loss: 1.0123\n",
            "Validation loss: 1.0223\n",
            "Training loss: 1.0123\n",
            "Validation loss: 1.0223\n",
            "Training loss: 1.0122\n",
            "Validation loss: 1.0222\n",
            "Training loss: 1.0122\n",
            "Validation loss: 1.0222\n",
            "Training loss: 1.0122\n",
            "Validation loss: 1.0222\n",
            "Training loss: 1.0122\n",
            "Validation loss: 1.0222\n",
            "Training loss: 1.0122\n",
            "Validation loss: 1.0222\n",
            "Training loss: 1.0122\n",
            "Validation loss: 1.0221\n",
            "Training loss: 1.0121\n",
            "Validation loss: 1.0221\n",
            "Training loss: 1.0121\n",
            "Validation loss: 1.0221\n",
            "Training loss: 1.0121\n",
            "Validation loss: 1.0221\n",
            "Training loss: 1.0121\n",
            "Validation loss: 1.0221\n",
            "Training loss: 1.0121\n",
            "Validation loss: 1.0221\n",
            "Training loss: 1.0121\n",
            "Validation loss: 1.0220\n",
            "Training loss: 1.0120\n",
            "Validation loss: 1.0220\n",
            "Training loss: 1.0120\n",
            "Validation loss: 1.0220\n",
            "Training loss: 1.0120\n",
            "Validation loss: 1.0220\n",
            "Training loss: 1.0120\n",
            "Validation loss: 1.0220\n",
            "Training loss: 1.0120\n",
            "Validation loss: 1.0219\n",
            "Training loss: 1.0119\n",
            "Validation loss: 1.0219\n",
            "Training loss: 1.0119\n",
            "Validation loss: 1.0219\n",
            "Training loss: 1.0119\n",
            "Validation loss: 1.0219\n",
            "Training loss: 1.0119\n",
            "Validation loss: 1.0219\n",
            "Training loss: 1.0119\n",
            "Validation loss: 1.0219\n",
            "Training loss: 1.0119\n",
            "Validation loss: 1.0218\n",
            "Training loss: 1.0118\n",
            "Validation loss: 1.0218\n",
            "Training loss: 1.0118\n",
            "Validation loss: 1.0218\n",
            "Training loss: 1.0118\n",
            "Validation loss: 1.0218\n",
            "Training loss: 1.0118\n",
            "Validation loss: 1.0218\n",
            "Training loss: 1.0118\n",
            "Validation loss: 1.0218\n",
            "Training loss: 1.0118\n",
            "Validation loss: 1.0217\n",
            "Training loss: 1.0117\n",
            "Validation loss: 1.0217\n",
            "Training loss: 1.0117\n",
            "Validation loss: 1.0217\n",
            "Training loss: 1.0117\n",
            "Validation loss: 1.0217\n",
            "Training loss: 1.0117\n",
            "Validation loss: 1.0217\n",
            "Training loss: 1.0117\n",
            "Validation loss: 1.0217\n",
            "Training loss: 1.0117\n",
            "Validation loss: 1.0216\n",
            "Training loss: 1.0116\n",
            "Validation loss: 1.0216\n",
            "Training loss: 1.0116\n",
            "Validation loss: 1.0216\n",
            "Training loss: 1.0116\n",
            "Validation loss: 1.0216\n",
            "Training loss: 1.0116\n",
            "Validation loss: 1.0216\n",
            "Training loss: 1.0116\n",
            "Validation loss: 1.0216\n",
            "Training loss: 1.0116\n",
            "Validation loss: 1.0215\n",
            "Training loss: 1.0115\n",
            "Validation loss: 1.0215\n",
            "Training loss: 1.0115\n",
            "Validation loss: 1.0215\n",
            "Training loss: 1.0115\n",
            "Validation loss: 1.0215\n",
            "Training loss: 1.0115\n",
            "Validation loss: 1.0215\n",
            "Training loss: 1.0115\n",
            "Validation loss: 1.0215\n",
            "Training loss: 1.0115\n",
            "Validation loss: 1.0214\n",
            "Training loss: 1.0114\n",
            "Validation loss: 1.0214\n",
            "Training loss: 1.0114\n",
            "Validation loss: 1.0214\n",
            "Training loss: 1.0114\n",
            "Validation loss: 1.0214\n",
            "Training loss: 1.0114\n",
            "Validation loss: 1.0214\n",
            "Training loss: 1.0114\n",
            "Validation loss: 1.0214\n",
            "Training loss: 1.0114\n",
            "Validation loss: 1.0213\n",
            "Training loss: 1.0114\n",
            "Validation loss: 1.0213\n",
            "Training loss: 1.0113\n",
            "Validation loss: 1.0213\n",
            "Training loss: 1.0113\n",
            "Validation loss: 1.0213\n",
            "Training loss: 1.0113\n",
            "Validation loss: 1.0213\n",
            "Training loss: 1.0113\n",
            "Validation loss: 1.0213\n",
            "Training loss: 1.0113\n",
            "Validation loss: 1.0212\n",
            "Training loss: 1.0113\n",
            "Validation loss: 1.0212\n",
            "Training loss: 1.0112\n",
            "Validation loss: 1.0212\n",
            "Training loss: 1.0112\n",
            "Validation loss: 1.0212\n",
            "Training loss: 1.0112\n",
            "Validation loss: 1.0212\n",
            "Training loss: 1.0112\n",
            "Validation loss: 1.0212\n",
            "Training loss: 1.0112\n",
            "Validation loss: 1.0212\n",
            "Training loss: 1.0112\n",
            "Validation loss: 1.0211\n",
            "Training loss: 1.0112\n",
            "Validation loss: 1.0211\n",
            "Training loss: 1.0111\n",
            "Validation loss: 1.0211\n",
            "Training loss: 1.0111\n",
            "Validation loss: 1.0211\n",
            "Training loss: 1.0111\n",
            "Validation loss: 1.0211\n",
            "Training loss: 1.0111\n",
            "Validation loss: 1.0211\n",
            "Training loss: 1.0111\n",
            "Validation loss: 1.0211\n",
            "Training loss: 1.0111\n",
            "Validation loss: 1.0210\n",
            "Training loss: 1.0111\n",
            "Validation loss: 1.0210\n",
            "Training loss: 1.0110\n",
            "Validation loss: 1.0210\n",
            "Training loss: 1.0110\n",
            "Validation loss: 1.0210\n",
            "Training loss: 1.0110\n",
            "Validation loss: 1.0210\n",
            "Training loss: 1.0110\n",
            "Validation loss: 1.0210\n",
            "Training loss: 1.0110\n",
            "Validation loss: 1.0209\n",
            "Training loss: 1.0110\n",
            "Validation loss: 1.0209\n",
            "Training loss: 1.0109\n",
            "Validation loss: 1.0209\n",
            "Training loss: 1.0109\n",
            "Validation loss: 1.0209\n",
            "Training loss: 1.0109\n",
            "Validation loss: 1.0209\n",
            "Training loss: 1.0109\n",
            "Validation loss: 1.0209\n",
            "Training loss: 1.0109\n",
            "Validation loss: 1.0209\n",
            "Training loss: 1.0109\n",
            "Validation loss: 1.0208\n",
            "Training loss: 1.0109\n",
            "Validation loss: 1.0208\n",
            "Training loss: 1.0108\n",
            "Validation loss: 1.0208\n",
            "Training loss: 1.0108\n",
            "Validation loss: 1.0208\n",
            "Training loss: 1.0108\n",
            "Validation loss: 1.0208\n",
            "Training loss: 1.0108\n",
            "Validation loss: 1.0208\n",
            "Training loss: 1.0108\n",
            "Validation loss: 1.0208\n",
            "Training loss: 1.0108\n",
            "Validation loss: 1.0207\n",
            "Training loss: 1.0108\n",
            "Validation loss: 1.0207\n",
            "Training loss: 1.0108\n",
            "Validation loss: 1.0207\n",
            "Training loss: 1.0107\n",
            "Validation loss: 1.0207\n",
            "Training loss: 1.0107\n",
            "Validation loss: 1.0207\n",
            "Training loss: 1.0107\n",
            "Validation loss: 1.0207\n",
            "Training loss: 1.0107\n",
            "Validation loss: 1.0207\n",
            "Training loss: 1.0107\n",
            "Validation loss: 1.0206\n",
            "Training loss: 1.0107\n",
            "Validation loss: 1.0206\n",
            "Training loss: 1.0107\n",
            "Validation loss: 1.0206\n",
            "Training loss: 1.0106\n",
            "Validation loss: 1.0206\n",
            "Training loss: 1.0106\n",
            "Validation loss: 1.0206\n",
            "Training loss: 1.0106\n",
            "Validation loss: 1.0206\n",
            "Training loss: 1.0106\n",
            "Validation loss: 1.0206\n",
            "Training loss: 1.0106\n",
            "Validation loss: 1.0206\n",
            "Training loss: 1.0106\n",
            "Validation loss: 1.0205\n",
            "Training loss: 1.0106\n",
            "Validation loss: 1.0205\n",
            "Training loss: 1.0106\n",
            "Validation loss: 1.0205\n",
            "Training loss: 1.0105\n",
            "Validation loss: 1.0205\n",
            "Training loss: 1.0105\n",
            "Validation loss: 1.0205\n",
            "Training loss: 1.0105\n",
            "Validation loss: 1.0205\n",
            "Training loss: 1.0105\n",
            "Validation loss: 1.0205\n",
            "Training loss: 1.0105\n",
            "Validation loss: 1.0204\n",
            "Training loss: 1.0105\n",
            "Validation loss: 1.0204\n",
            "Training loss: 1.0105\n",
            "Validation loss: 1.0204\n",
            "Training loss: 1.0104\n",
            "Validation loss: 1.0204\n",
            "Training loss: 1.0104\n",
            "Validation loss: 1.0204\n",
            "Training loss: 1.0104\n",
            "Validation loss: 1.0204\n",
            "Training loss: 1.0104\n",
            "Validation loss: 1.0204\n",
            "Training loss: 1.0104\n",
            "Validation loss: 1.0204\n",
            "Training loss: 1.0104\n",
            "Validation loss: 1.0203\n",
            "Training loss: 1.0104\n",
            "Validation loss: 1.0203\n",
            "Training loss: 1.0104\n",
            "Validation loss: 1.0203\n",
            "Training loss: 1.0103\n",
            "Validation loss: 1.0203\n",
            "Training loss: 1.0103\n",
            "Validation loss: 1.0203\n",
            "Training loss: 1.0103\n",
            "Validation loss: 1.0203\n",
            "Training loss: 1.0103\n",
            "Validation loss: 1.0203\n",
            "Training loss: 1.0103\n",
            "Validation loss: 1.0203\n",
            "Training loss: 1.0103\n",
            "Validation loss: 1.0202\n",
            "Training loss: 1.0103\n",
            "Validation loss: 1.0202\n",
            "Training loss: 1.0103\n",
            "Validation loss: 1.0202\n",
            "Training loss: 1.0102\n",
            "Validation loss: 1.0202\n",
            "Training loss: 1.0102\n",
            "Validation loss: 1.0202\n",
            "Training loss: 1.0102\n",
            "Validation loss: 1.0202\n",
            "Training loss: 1.0102\n",
            "Validation loss: 1.0202\n",
            "Training loss: 1.0102\n",
            "Validation loss: 1.0202\n",
            "Training loss: 1.0102\n",
            "Validation loss: 1.0201\n",
            "Training loss: 1.0102\n",
            "Validation loss: 1.0201\n",
            "Training loss: 1.0102\n",
            "Validation loss: 1.0201\n",
            "Training loss: 1.0102\n",
            "Validation loss: 1.0201\n",
            "Training loss: 1.0101\n",
            "Validation loss: 1.0201\n",
            "Training loss: 1.0101\n",
            "Validation loss: 1.0201\n",
            "Training loss: 1.0101\n",
            "Validation loss: 1.0201\n",
            "Training loss: 1.0101\n",
            "Validation loss: 1.0201\n",
            "Training loss: 1.0101\n",
            "Validation loss: 1.0200\n",
            "Training loss: 1.0101\n",
            "Validation loss: 1.0200\n",
            "Training loss: 1.0101\n",
            "Validation loss: 1.0200\n",
            "Training loss: 1.0101\n",
            "Validation loss: 1.0200\n",
            "Training loss: 1.0100\n",
            "Validation loss: 1.0200\n",
            "Training loss: 1.0100\n",
            "Validation loss: 1.0200\n",
            "Training loss: 1.0100\n",
            "Validation loss: 1.0200\n",
            "Training loss: 1.0100\n",
            "Validation loss: 1.0200\n",
            "Training loss: 1.0100\n",
            "Validation loss: 1.0200\n",
            "Training loss: 1.0100\n",
            "Validation loss: 1.0199\n",
            "Training loss: 1.0100\n",
            "Validation loss: 1.0199\n",
            "Training loss: 1.0100\n",
            "Validation loss: 1.0199\n",
            "Training loss: 1.0100\n",
            "Validation loss: 1.0199\n",
            "Training loss: 1.0099\n",
            "Validation loss: 1.0199\n",
            "Training loss: 1.0099\n",
            "Validation loss: 1.0199\n",
            "Training loss: 1.0099\n",
            "Validation loss: 1.0199\n",
            "Training loss: 1.0099\n",
            "Validation loss: 1.0199\n",
            "Training loss: 1.0099\n",
            "Validation loss: 1.0198\n",
            "Training loss: 1.0099\n",
            "Validation loss: 1.0198\n",
            "Training loss: 1.0099\n",
            "Validation loss: 1.0198\n",
            "Training loss: 1.0099\n",
            "Validation loss: 1.0198\n",
            "Training loss: 1.0099\n",
            "Validation loss: 1.0198\n",
            "Training loss: 1.0098\n",
            "Validation loss: 1.0198\n",
            "Training loss: 1.0098\n",
            "Validation loss: 1.0198\n",
            "Training loss: 1.0098\n",
            "Validation loss: 1.0198\n",
            "Training loss: 1.0098\n",
            "Validation loss: 1.0198\n",
            "Training loss: 1.0098\n",
            "Validation loss: 1.0197\n",
            "Training loss: 1.0098\n",
            "Validation loss: 1.0197\n",
            "Training loss: 1.0098\n",
            "Validation loss: 1.0197\n",
            "Training loss: 1.0098\n",
            "Validation loss: 1.0197\n",
            "Training loss: 1.0098\n",
            "Validation loss: 1.0197\n",
            "Training loss: 1.0097\n",
            "Validation loss: 1.0197\n",
            "Training loss: 1.0097\n",
            "Validation loss: 1.0197\n",
            "Training loss: 1.0097\n",
            "Validation loss: 1.0197\n",
            "Training loss: 1.0097\n",
            "Validation loss: 1.0197\n",
            "Training loss: 1.0097\n",
            "Validation loss: 1.0196\n",
            "Training loss: 1.0097\n",
            "Validation loss: 1.0196\n",
            "Training loss: 1.0097\n",
            "Validation loss: 1.0196\n",
            "Training loss: 1.0097\n",
            "Validation loss: 1.0196\n",
            "Training loss: 1.0097\n",
            "Validation loss: 1.0196\n",
            "Training loss: 1.0096\n",
            "Validation loss: 1.0196\n",
            "Training loss: 1.0096\n",
            "Validation loss: 1.0196\n",
            "Training loss: 1.0096\n",
            "Validation loss: 1.0196\n",
            "Training loss: 1.0096\n",
            "Validation loss: 1.0196\n",
            "Training loss: 1.0096\n",
            "Validation loss: 1.0196\n",
            "Training loss: 1.0096\n",
            "Validation loss: 1.0195\n",
            "Training loss: 1.0096\n",
            "Validation loss: 1.0195\n",
            "Training loss: 1.0096\n",
            "Validation loss: 1.0195\n",
            "Training loss: 1.0096\n",
            "Validation loss: 1.0195\n",
            "Training loss: 1.0096\n",
            "Validation loss: 1.0195\n",
            "Training loss: 1.0095\n",
            "Validation loss: 1.0195\n",
            "Training loss: 1.0095\n",
            "Validation loss: 1.0195\n",
            "Training loss: 1.0095\n",
            "Validation loss: 1.0195\n",
            "Training loss: 1.0095\n",
            "Validation loss: 1.0195\n",
            "Training loss: 1.0095\n",
            "Validation loss: 1.0194\n",
            "Training loss: 1.0095\n",
            "Validation loss: 1.0194\n",
            "Training loss: 1.0095\n",
            "Validation loss: 1.0194\n",
            "Training loss: 1.0095\n",
            "Validation loss: 1.0194\n",
            "Training loss: 1.0095\n",
            "Validation loss: 1.0194\n",
            "Training loss: 1.0095\n",
            "Validation loss: 1.0194\n",
            "Training loss: 1.0094\n",
            "Validation loss: 1.0194\n",
            "Training loss: 1.0094\n",
            "Validation loss: 1.0194\n",
            "Training loss: 1.0094\n",
            "Validation loss: 1.0194\n",
            "Training loss: 1.0094\n",
            "Validation loss: 1.0194\n",
            "Training loss: 1.0094\n",
            "Validation loss: 1.0193\n",
            "Training loss: 1.0094\n",
            "Validation loss: 1.0193\n",
            "Training loss: 1.0094\n",
            "Validation loss: 1.0193\n",
            "Training loss: 1.0094\n",
            "Validation loss: 1.0193\n",
            "Training loss: 1.0094\n",
            "Validation loss: 1.0193\n",
            "Training loss: 1.0094\n",
            "Validation loss: 1.0193\n",
            "Training loss: 1.0093\n",
            "Validation loss: 1.0193\n",
            "Training loss: 1.0093\n",
            "Validation loss: 1.0193\n",
            "Training loss: 1.0093\n",
            "Validation loss: 1.0193\n",
            "Training loss: 1.0093\n",
            "Validation loss: 1.0193\n",
            "Training loss: 1.0093\n",
            "Validation loss: 1.0193\n",
            "Training loss: 1.0093\n",
            "Validation loss: 1.0192\n",
            "Training loss: 1.0093\n",
            "Validation loss: 1.0192\n",
            "Training loss: 1.0093\n",
            "Validation loss: 1.0192\n",
            "Training loss: 1.0093\n",
            "Validation loss: 1.0192\n",
            "Training loss: 1.0093\n",
            "Validation loss: 1.0192\n",
            "Training loss: 1.0093\n",
            "Validation loss: 1.0192\n",
            "Training loss: 1.0092\n",
            "Validation loss: 1.0192\n",
            "Training loss: 1.0092\n",
            "Validation loss: 1.0192\n",
            "Training loss: 1.0092\n",
            "Validation loss: 1.0192\n",
            "Training loss: 1.0092\n",
            "Validation loss: 1.0192\n",
            "Training loss: 1.0092\n",
            "Validation loss: 1.0191\n",
            "Training loss: 1.0092\n",
            "Validation loss: 1.0191\n",
            "Training loss: 1.0092\n",
            "Validation loss: 1.0191\n",
            "Training loss: 1.0092\n",
            "Validation loss: 1.0191\n",
            "Training loss: 1.0092\n",
            "Validation loss: 1.0191\n",
            "Training loss: 1.0092\n",
            "Validation loss: 1.0191\n",
            "Training loss: 1.0091\n",
            "Validation loss: 1.0191\n",
            "Training loss: 1.0091\n",
            "Validation loss: 1.0191\n",
            "Training loss: 1.0091\n",
            "Validation loss: 1.0191\n",
            "Training loss: 1.0091\n",
            "Validation loss: 1.0191\n",
            "Training loss: 1.0091\n",
            "Validation loss: 1.0191\n",
            "Training loss: 1.0091\n",
            "Validation loss: 1.0190\n",
            "Training loss: 1.0091\n",
            "Validation loss: 1.0190\n",
            "Training loss: 1.0091\n",
            "Validation loss: 1.0190\n",
            "Training loss: 1.0091\n",
            "Validation loss: 1.0190\n",
            "Training loss: 1.0091\n",
            "Validation loss: 1.0190\n",
            "Training loss: 1.0091\n",
            "Validation loss: 1.0190\n",
            "Training loss: 1.0091\n",
            "Validation loss: 1.0190\n",
            "Training loss: 1.0090\n",
            "Validation loss: 1.0190\n",
            "Training loss: 1.0090\n",
            "Validation loss: 1.0190\n",
            "Training loss: 1.0090\n",
            "Validation loss: 1.0190\n",
            "Training loss: 1.0090\n",
            "Validation loss: 1.0190\n",
            "Training loss: 1.0090\n",
            "Validation loss: 1.0189\n",
            "Training loss: 1.0090\n",
            "Validation loss: 1.0189\n",
            "Training loss: 1.0090\n",
            "Validation loss: 1.0189\n",
            "Training loss: 1.0090\n",
            "Validation loss: 1.0189\n",
            "Training loss: 1.0090\n",
            "Validation loss: 1.0189\n",
            "Training loss: 1.0090\n",
            "Validation loss: 1.0189\n",
            "Training loss: 1.0090\n",
            "Validation loss: 1.0189\n",
            "Training loss: 1.0089\n",
            "Validation loss: 1.0189\n",
            "Training loss: 1.0089\n",
            "Validation loss: 1.0189\n",
            "Training loss: 1.0089\n",
            "Validation loss: 1.0189\n",
            "Training loss: 1.0089\n",
            "Validation loss: 1.0189\n",
            "Training loss: 1.0089\n",
            "Validation loss: 1.0189\n",
            "Training loss: 1.0089\n",
            "Validation loss: 1.0188\n",
            "Training loss: 1.0089\n",
            "Validation loss: 1.0188\n",
            "Training loss: 1.0089\n",
            "Validation loss: 1.0188\n",
            "Training loss: 1.0089\n",
            "Validation loss: 1.0188\n",
            "Training loss: 1.0089\n",
            "Validation loss: 1.0188\n",
            "Training loss: 1.0089\n",
            "Validation loss: 1.0188\n",
            "Training loss: 1.0089\n",
            "Validation loss: 1.0188\n",
            "Training loss: 1.0088\n",
            "Validation loss: 1.0188\n",
            "Training loss: 1.0088\n",
            "Validation loss: 1.0188\n",
            "Training loss: 1.0088\n",
            "Validation loss: 1.0188\n",
            "Training loss: 1.0088\n",
            "Validation loss: 1.0188\n",
            "Training loss: 1.0088\n",
            "Validation loss: 1.0188\n",
            "Training loss: 1.0088\n",
            "Validation loss: 1.0187\n",
            "Training loss: 1.0088\n",
            "Validation loss: 1.0187\n",
            "Training loss: 1.0088\n",
            "Validation loss: 1.0187\n",
            "Training loss: 1.0088\n",
            "Validation loss: 1.0187\n",
            "Training loss: 1.0088\n",
            "Validation loss: 1.0187\n",
            "Training loss: 1.0088\n",
            "Validation loss: 1.0187\n",
            "Training loss: 1.0088\n",
            "Validation loss: 1.0187\n",
            "Training loss: 1.0088\n",
            "Validation loss: 1.0187\n",
            "Training loss: 1.0087\n",
            "Validation loss: 1.0187\n",
            "Training loss: 1.0087\n",
            "Validation loss: 1.0187\n",
            "Training loss: 1.0087\n",
            "Validation loss: 1.0187\n",
            "Training loss: 1.0087\n",
            "Validation loss: 1.0187\n",
            "Training loss: 1.0087\n",
            "Validation loss: 1.0186\n",
            "Training loss: 1.0087\n",
            "Validation loss: 1.0186\n",
            "Training loss: 1.0087\n",
            "Validation loss: 1.0186\n",
            "Training loss: 1.0087\n",
            "Validation loss: 1.0186\n",
            "Training loss: 1.0087\n",
            "Validation loss: 1.0186\n",
            "Training loss: 1.0087\n",
            "Validation loss: 1.0186\n",
            "Training loss: 1.0087\n",
            "Validation loss: 1.0186\n",
            "Training loss: 1.0087\n",
            "Validation loss: 1.0186\n",
            "Training loss: 1.0087\n",
            "Validation loss: 1.0186\n",
            "Training loss: 1.0086\n",
            "Validation loss: 1.0186\n",
            "Training loss: 1.0086\n",
            "Validation loss: 1.0186\n",
            "Training loss: 1.0086\n",
            "Validation loss: 1.0186\n",
            "Training loss: 1.0086\n",
            "Validation loss: 1.0186\n",
            "Training loss: 1.0086\n",
            "Validation loss: 1.0185\n",
            "Training loss: 1.0086\n",
            "Validation loss: 1.0185\n",
            "Training loss: 1.0086\n",
            "Validation loss: 1.0185\n",
            "Training loss: 1.0086\n",
            "Validation loss: 1.0185\n",
            "Training loss: 1.0086\n",
            "Validation loss: 1.0185\n",
            "Training loss: 1.0086\n",
            "Validation loss: 1.0185\n",
            "Training loss: 1.0086\n",
            "Validation loss: 1.0185\n",
            "Training loss: 1.0086\n",
            "Validation loss: 1.0185\n",
            "Training loss: 1.0086\n",
            "Validation loss: 1.0185\n",
            "Training loss: 1.0085\n",
            "Validation loss: 1.0185\n",
            "Training loss: 1.0085\n",
            "Validation loss: 1.0185\n",
            "Training loss: 1.0085\n",
            "Validation loss: 1.0185\n",
            "Training loss: 1.0085\n",
            "Validation loss: 1.0185\n",
            "Training loss: 1.0085\n",
            "Validation loss: 1.0184\n",
            "Training loss: 1.0085\n",
            "Validation loss: 1.0184\n",
            "Training loss: 1.0085\n",
            "Validation loss: 1.0184\n",
            "Training loss: 1.0085\n",
            "Validation loss: 1.0184\n",
            "Training loss: 1.0085\n",
            "Validation loss: 1.0184\n",
            "Training loss: 1.0085\n",
            "Validation loss: 1.0184\n",
            "Training loss: 1.0085\n",
            "Validation loss: 1.0184\n",
            "Training loss: 1.0085\n",
            "Validation loss: 1.0184\n",
            "Training loss: 1.0085\n",
            "Validation loss: 1.0184\n",
            "Training loss: 1.0085\n",
            "Validation loss: 1.0184\n",
            "Training loss: 1.0084\n",
            "Validation loss: 1.0184\n",
            "Training loss: 1.0084\n",
            "Validation loss: 1.0184\n",
            "Training loss: 1.0084\n",
            "Validation loss: 1.0184\n",
            "Training loss: 1.0084\n",
            "Validation loss: 1.0184\n",
            "Training loss: 1.0084\n",
            "Validation loss: 1.0183\n",
            "Training loss: 1.0084\n",
            "Validation loss: 1.0183\n",
            "Training loss: 1.0084\n",
            "Validation loss: 1.0183\n",
            "Training loss: 1.0084\n",
            "Validation loss: 1.0183\n",
            "Training loss: 1.0084\n",
            "Validation loss: 1.0183\n",
            "Training loss: 1.0084\n",
            "Validation loss: 1.0183\n",
            "Training loss: 1.0084\n",
            "Validation loss: 1.0183\n",
            "Training loss: 1.0084\n",
            "Validation loss: 1.0183\n",
            "Training loss: 1.0084\n",
            "Validation loss: 1.0183\n",
            "Training loss: 1.0084\n",
            "Validation loss: 1.0183\n",
            "Training loss: 1.0083\n",
            "Validation loss: 1.0183\n",
            "Training loss: 1.0083\n",
            "Validation loss: 1.0183\n",
            "Training loss: 1.0083\n",
            "Validation loss: 1.0183\n",
            "Training loss: 1.0083\n",
            "Validation loss: 1.0183\n",
            "Training loss: 1.0083\n",
            "Validation loss: 1.0182\n",
            "Training loss: 1.0083\n",
            "Validation loss: 1.0182\n",
            "Training loss: 1.0083\n",
            "Validation loss: 1.0182\n",
            "Training loss: 1.0083\n",
            "Validation loss: 1.0182\n",
            "Training loss: 1.0083\n",
            "Validation loss: 1.0182\n",
            "Training loss: 1.0083\n",
            "Validation loss: 1.0182\n",
            "Training loss: 1.0083\n",
            "Validation loss: 1.0182\n",
            "Training loss: 1.0083\n",
            "Validation loss: 1.0182\n",
            "Training loss: 1.0083\n",
            "Validation loss: 1.0182\n",
            "Training loss: 1.0083\n",
            "Validation loss: 1.0182\n",
            "Training loss: 1.0083\n",
            "Validation loss: 1.0182\n",
            "Training loss: 1.0082\n",
            "Validation loss: 1.0182\n",
            "Training loss: 1.0082\n",
            "Validation loss: 1.0182\n",
            "Training loss: 1.0082\n",
            "Validation loss: 1.0182\n",
            "Training loss: 1.0082\n",
            "Validation loss: 1.0182\n",
            "Training loss: 1.0082\n",
            "Validation loss: 1.0181\n",
            "Training loss: 1.0082\n",
            "Validation loss: 1.0181\n",
            "Training loss: 1.0082\n",
            "Validation loss: 1.0181\n",
            "Training loss: 1.0082\n",
            "Validation loss: 1.0181\n",
            "Training loss: 1.0082\n",
            "Validation loss: 1.0181\n",
            "Training loss: 1.0082\n",
            "Validation loss: 1.0181\n",
            "Training loss: 1.0082\n",
            "Validation loss: 1.0181\n",
            "Training loss: 1.0082\n",
            "Validation loss: 1.0181\n",
            "Training loss: 1.0082\n",
            "Validation loss: 1.0181\n",
            "Training loss: 1.0082\n",
            "Validation loss: 1.0181\n",
            "Training loss: 1.0082\n",
            "Validation loss: 1.0181\n",
            "Training loss: 1.0082\n",
            "Validation loss: 1.0181\n",
            "Training loss: 1.0081\n",
            "Validation loss: 1.0181\n",
            "Training loss: 1.0081\n",
            "Validation loss: 1.0181\n",
            "Training loss: 1.0081\n",
            "Validation loss: 1.0181\n",
            "Training loss: 1.0081\n",
            "Validation loss: 1.0181\n",
            "Training loss: 1.0081\n",
            "Validation loss: 1.0180\n",
            "Training loss: 1.0081\n",
            "Validation loss: 1.0180\n",
            "Training loss: 1.0081\n",
            "Validation loss: 1.0180\n",
            "Training loss: 1.0081\n",
            "Validation loss: 1.0180\n",
            "Training loss: 1.0081\n",
            "Validation loss: 1.0180\n",
            "Training loss: 1.0081\n",
            "Validation loss: 1.0180\n",
            "Training loss: 1.0081\n",
            "Validation loss: 1.0180\n",
            "Training loss: 1.0081\n",
            "Validation loss: 1.0180\n",
            "Training loss: 1.0081\n",
            "Validation loss: 1.0180\n",
            "Training loss: 1.0081\n",
            "Validation loss: 1.0180\n",
            "Training loss: 1.0081\n",
            "Validation loss: 1.0180\n",
            "Training loss: 1.0081\n",
            "Validation loss: 1.0180\n",
            "Training loss: 1.0080\n",
            "Validation loss: 1.0180\n",
            "Training loss: 1.0080\n",
            "Validation loss: 1.0180\n",
            "Training loss: 1.0080\n",
            "Validation loss: 1.0180\n",
            "Training loss: 1.0080\n",
            "Validation loss: 1.0180\n",
            "Training loss: 1.0080\n",
            "Validation loss: 1.0179\n",
            "Training loss: 1.0080\n",
            "Validation loss: 1.0179\n",
            "Training loss: 1.0080\n",
            "Validation loss: 1.0179\n",
            "Training loss: 1.0080\n",
            "Validation loss: 1.0179\n",
            "Training loss: 1.0080\n",
            "Validation loss: 1.0179\n",
            "Training loss: 1.0080\n",
            "Validation loss: 1.0179\n",
            "Training loss: 1.0080\n",
            "Validation loss: 1.0179\n",
            "Training loss: 1.0080\n",
            "Validation loss: 1.0179\n",
            "Training loss: 1.0080\n",
            "Validation loss: 1.0179\n",
            "Training loss: 1.0080\n",
            "Validation loss: 1.0179\n",
            "Training loss: 1.0080\n",
            "Validation loss: 1.0179\n",
            "Training loss: 1.0080\n",
            "Validation loss: 1.0179\n",
            "Training loss: 1.0080\n",
            "Validation loss: 1.0179\n",
            "Training loss: 1.0080\n",
            "Validation loss: 1.0179\n",
            "Training loss: 1.0079\n",
            "Validation loss: 1.0179\n",
            "Training loss: 1.0079\n",
            "Validation loss: 1.0179\n",
            "Training loss: 1.0079\n",
            "Validation loss: 1.0179\n",
            "Training loss: 1.0079\n",
            "Validation loss: 1.0179\n",
            "Training loss: 1.0079\n",
            "Validation loss: 1.0178\n",
            "Training loss: 1.0079\n",
            "Validation loss: 1.0178\n",
            "Training loss: 1.0079\n",
            "Validation loss: 1.0178\n",
            "Training loss: 1.0079\n",
            "Validation loss: 1.0178\n",
            "Training loss: 1.0079\n",
            "Validation loss: 1.0178\n",
            "Training loss: 1.0079\n",
            "Validation loss: 1.0178\n",
            "Training loss: 1.0079\n",
            "Validation loss: 1.0178\n",
            "Training loss: 1.0079\n",
            "Validation loss: 1.0178\n",
            "Training loss: 1.0079\n",
            "Validation loss: 1.0178\n",
            "Training loss: 1.0079\n",
            "Validation loss: 1.0178\n",
            "Training loss: 1.0079\n",
            "Validation loss: 1.0178\n",
            "Training loss: 1.0079\n",
            "Validation loss: 1.0178\n",
            "Training loss: 1.0079\n",
            "Validation loss: 1.0178\n",
            "Training loss: 1.0079\n",
            "Validation loss: 1.0178\n",
            "Training loss: 1.0078\n",
            "Validation loss: 1.0178\n",
            "Training loss: 1.0078\n",
            "Validation loss: 1.0178\n",
            "Training loss: 1.0078\n",
            "Validation loss: 1.0178\n",
            "Training loss: 1.0078\n",
            "Validation loss: 1.0178\n",
            "Training loss: 1.0078\n",
            "Validation loss: 1.0177\n",
            "Training loss: 1.0078\n",
            "Validation loss: 1.0177\n",
            "Training loss: 1.0078\n",
            "Validation loss: 1.0177\n",
            "Training loss: 1.0078\n",
            "Validation loss: 1.0177\n",
            "Training loss: 1.0078\n",
            "Validation loss: 1.0177\n",
            "Training loss: 1.0078\n",
            "Validation loss: 1.0177\n",
            "Training loss: 1.0078\n",
            "Validation loss: 1.0177\n",
            "Training loss: 1.0078\n",
            "Validation loss: 1.0177\n",
            "Training loss: 1.0078\n",
            "Validation loss: 1.0177\n",
            "Training loss: 1.0078\n",
            "Validation loss: 1.0177\n",
            "Training loss: 1.0078\n",
            "Validation loss: 1.0177\n",
            "Training loss: 1.0078\n",
            "Validation loss: 1.0177\n",
            "Training loss: 1.0078\n",
            "Validation loss: 1.0177\n",
            "Training loss: 1.0078\n",
            "Validation loss: 1.0177\n",
            "Training loss: 1.0078\n",
            "Validation loss: 1.0177\n",
            "Training loss: 1.0077\n",
            "Validation loss: 1.0177\n",
            "Training loss: 1.0077\n",
            "Validation loss: 1.0177\n",
            "Training loss: 1.0077\n",
            "Validation loss: 1.0177\n",
            "Training loss: 1.0077\n",
            "Validation loss: 1.0177\n",
            "Training loss: 1.0077\n",
            "Validation loss: 1.0176\n",
            "Training loss: 1.0077\n",
            "Validation loss: 1.0176\n",
            "Training loss: 1.0077\n",
            "Validation loss: 1.0176\n",
            "Training loss: 1.0077\n",
            "Validation loss: 1.0176\n",
            "Training loss: 1.0077\n",
            "Validation loss: 1.0176\n",
            "Training loss: 1.0077\n",
            "Validation loss: 1.0176\n",
            "Training loss: 1.0077\n",
            "Validation loss: 1.0176\n",
            "Training loss: 1.0077\n",
            "Validation loss: 1.0176\n",
            "Training loss: 1.0077\n",
            "Validation loss: 1.0176\n",
            "Training loss: 1.0077\n",
            "Validation loss: 1.0176\n",
            "Training loss: 1.0077\n",
            "Validation loss: 1.0176\n",
            "Training loss: 1.0077\n",
            "Validation loss: 1.0176\n",
            "Training loss: 1.0077\n",
            "Validation loss: 1.0176\n",
            "Training loss: 1.0077\n",
            "Validation loss: 1.0176\n",
            "Training loss: 1.0077\n",
            "Validation loss: 1.0176\n",
            "Training loss: 1.0077\n",
            "Validation loss: 1.0176\n",
            "Training loss: 1.0076\n",
            "Validation loss: 1.0176\n",
            "Training loss: 1.0076\n",
            "Validation loss: 1.0176\n",
            "Training loss: 1.0076\n",
            "Validation loss: 1.0176\n",
            "Training loss: 1.0076\n",
            "Validation loss: 1.0176\n",
            "Training loss: 1.0076\n",
            "Validation loss: 1.0175\n",
            "Training loss: 1.0076\n",
            "Validation loss: 1.0175\n",
            "Training loss: 1.0076\n",
            "Validation loss: 1.0175\n",
            "Training loss: 1.0076\n",
            "Validation loss: 1.0175\n",
            "Training loss: 1.0076\n",
            "Validation loss: 1.0175\n",
            "Training loss: 1.0076\n",
            "Validation loss: 1.0175\n",
            "Training loss: 1.0076\n",
            "Validation loss: 1.0175\n",
            "Training loss: 1.0076\n",
            "Validation loss: 1.0175\n",
            "Training loss: 1.0076\n",
            "Validation loss: 1.0175\n",
            "Training loss: 1.0076\n",
            "Validation loss: 1.0175\n",
            "Training loss: 1.0076\n",
            "Validation loss: 1.0175\n",
            "Training loss: 1.0076\n",
            "Validation loss: 1.0175\n",
            "Training loss: 1.0076\n",
            "Validation loss: 1.0175\n",
            "Training loss: 1.0076\n",
            "Validation loss: 1.0175\n",
            "Training loss: 1.0076\n",
            "Validation loss: 1.0175\n",
            "Training loss: 1.0076\n",
            "Validation loss: 1.0175\n",
            "Training loss: 1.0076\n",
            "Validation loss: 1.0175\n",
            "Training loss: 1.0076\n",
            "Validation loss: 1.0175\n",
            "Training loss: 1.0075\n",
            "Validation loss: 1.0175\n",
            "Training loss: 1.0075\n",
            "Validation loss: 1.0175\n",
            "Training loss: 1.0075\n",
            "Validation loss: 1.0175\n",
            "Training loss: 1.0075\n",
            "Validation loss: 1.0175\n",
            "Training loss: 1.0075\n",
            "Validation loss: 1.0174\n",
            "Training loss: 1.0075\n",
            "Validation loss: 1.0174\n",
            "Training loss: 1.0075\n",
            "Validation loss: 1.0174\n",
            "Training loss: 1.0075\n",
            "Validation loss: 1.0174\n",
            "Training loss: 1.0075\n",
            "Validation loss: 1.0174\n",
            "Training loss: 1.0075\n",
            "Validation loss: 1.0174\n",
            "Training loss: 1.0075\n",
            "Validation loss: 1.0174\n",
            "Training loss: 1.0075\n",
            "Validation loss: 1.0174\n",
            "Training loss: 1.0075\n",
            "Validation loss: 1.0174\n",
            "Training loss: 1.0075\n",
            "Validation loss: 1.0174\n",
            "Training loss: 1.0075\n",
            "Validation loss: 1.0174\n",
            "Training loss: 1.0075\n",
            "Validation loss: 1.0174\n",
            "Training loss: 1.0075\n",
            "Validation loss: 1.0174\n",
            "Training loss: 1.0075\n",
            "Validation loss: 1.0174\n",
            "Training loss: 1.0075\n",
            "Validation loss: 1.0174\n",
            "Training loss: 1.0075\n",
            "Validation loss: 1.0174\n",
            "Training loss: 1.0075\n",
            "Validation loss: 1.0174\n",
            "Training loss: 1.0075\n",
            "Validation loss: 1.0174\n",
            "Training loss: 1.0075\n",
            "Validation loss: 1.0174\n",
            "Training loss: 1.0074\n",
            "Validation loss: 1.0174\n",
            "Training loss: 1.0074\n",
            "Validation loss: 1.0174\n",
            "Training loss: 1.0074\n",
            "Validation loss: 1.0174\n",
            "Training loss: 1.0074\n",
            "Validation loss: 1.0174\n",
            "Training loss: 1.0074\n",
            "Validation loss: 1.0173\n",
            "Training loss: 1.0074\n",
            "Validation loss: 1.0173\n",
            "Training loss: 1.0074\n",
            "Validation loss: 1.0173\n",
            "Training loss: 1.0074\n",
            "Validation loss: 1.0173\n",
            "Training loss: 1.0074\n",
            "Validation loss: 1.0173\n",
            "Training loss: 1.0074\n",
            "Validation loss: 1.0173\n",
            "Training loss: 1.0074\n",
            "Validation loss: 1.0173\n",
            "Training loss: 1.0074\n",
            "Validation loss: 1.0173\n",
            "Training loss: 1.0074\n",
            "Validation loss: 1.0173\n",
            "Training loss: 1.0074\n",
            "Validation loss: 1.0173\n",
            "Training loss: 1.0074\n",
            "Validation loss: 1.0173\n",
            "Training loss: 1.0074\n",
            "Validation loss: 1.0173\n",
            "Training loss: 1.0074\n",
            "Validation loss: 1.0173\n",
            "Training loss: 1.0074\n",
            "Validation loss: 1.0173\n",
            "Training loss: 1.0074\n",
            "Validation loss: 1.0173\n",
            "Training loss: 1.0074\n",
            "Validation loss: 1.0173\n",
            "Training loss: 1.0074\n",
            "Validation loss: 1.0173\n",
            "Training loss: 1.0074\n",
            "Validation loss: 1.0173\n",
            "Training loss: 1.0074\n",
            "Validation loss: 1.0173\n",
            "Training loss: 1.0074\n",
            "Validation loss: 1.0173\n",
            "Training loss: 1.0074\n",
            "Validation loss: 1.0173\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0173\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0173\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0173\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0173\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0165\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0066\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0166\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0067\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0167\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0068\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0168\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0169\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0069\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0170\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0070\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0171\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0071\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0172\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0173\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0173\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0173\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0173\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0173\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0173\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0173\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0173\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0173\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0173\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0173\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0173\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0173\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0173\n",
            "Training loss: 1.0072\n",
            "Validation loss: 1.0173\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0173\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0173\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0173\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0173\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0173\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0173\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0173\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0173\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0173\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0173\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0173\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0173\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0173\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0173\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0173\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0173\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0173\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0174\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0174\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0174\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0174\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0174\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0174\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0174\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0174\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0174\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0174\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0174\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0174\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0174\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0174\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0174\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0174\n",
            "Training loss: 1.0073\n",
            "Validation loss: 1.0174\n",
            "Training loss: 1.0074\n",
            "Validation loss: 1.0174\n",
            "Training loss: 1.0074\n",
            "Validation loss: 1.0174\n",
            "Training loss: 1.0074\n",
            "Validation loss: 1.0174\n",
            "Training loss: 1.0074\n",
            "Validation loss: 1.0174\n",
            "Training loss: 1.0074\n",
            "Validation loss: 1.0174\n",
            "Training loss: 1.0074\n",
            "Validation loss: 1.0174\n",
            "Training loss: 1.0074\n",
            "Validation loss: 1.0174\n",
            "Training loss: 1.0074\n",
            "Validation loss: 1.0174\n",
            "Training loss: 1.0074\n",
            "Validation loss: 1.0174\n",
            "Training loss: 1.0074\n",
            "Validation loss: 1.0174\n",
            "Training loss: 1.0074\n",
            "Validation loss: 1.0174\n",
            "Training loss: 1.0074\n",
            "Validation loss: 1.0174\n",
            "Training loss: 1.0074\n",
            "Validation loss: 1.0174\n",
            "Training loss: 1.0074\n",
            "Validation loss: 1.0175\n",
            "Training loss: 1.0074\n",
            "Validation loss: 1.0175\n",
            "Training loss: 1.0074\n",
            "Validation loss: 1.0175\n",
            "Training loss: 1.0074\n",
            "Validation loss: 1.0175\n",
            "Training loss: 1.0074\n",
            "Validation loss: 1.0175\n",
            "Training loss: 1.0074\n",
            "Validation loss: 1.0175\n",
            "Training loss: 1.0074\n",
            "Validation loss: 1.0175\n",
            "Training loss: 1.0074\n",
            "Validation loss: 1.0175\n",
            "Training loss: 1.0074\n",
            "Validation loss: 1.0175\n",
            "Training loss: 1.0074\n",
            "Validation loss: 1.0175\n",
            "Training loss: 1.0074\n",
            "Validation loss: 1.0175\n",
            "Training loss: 1.0074\n",
            "Validation loss: 1.0175\n",
            "Training loss: 1.0074\n",
            "Validation loss: 1.0175\n",
            "Training loss: 1.0074\n",
            "Validation loss: 1.0175\n",
            "Training loss: 1.0074\n",
            "Validation loss: 1.0175\n",
            "Training loss: 1.0074\n",
            "Validation loss: 1.0175\n",
            "Training loss: 1.0074\n",
            "Validation loss: 1.0175\n",
            "Training loss: 1.0074\n",
            "Validation loss: 1.0175\n",
            "Training loss: 1.0074\n",
            "Validation loss: 1.0175\n",
            "Training loss: 1.0075\n",
            "Validation loss: 1.0175\n",
            "Training loss: 1.0075\n",
            "Validation loss: 1.0175\n",
            "Training loss: 1.0075\n",
            "Validation loss: 1.0175\n",
            "Training loss: 1.0075\n",
            "Validation loss: 1.0175\n",
            "Training loss: 1.0075\n",
            "Validation loss: 1.0175\n",
            "Training loss: 1.0075\n",
            "Validation loss: 1.0175\n",
            "Training loss: 1.0075\n",
            "Validation loss: 1.0175\n",
            "Training loss: 1.0075\n",
            "Validation loss: 1.0175\n",
            "Training loss: 1.0075\n",
            "Validation loss: 1.0175\n",
            "Training loss: 1.0075\n",
            "Validation loss: 1.0175\n",
            "Training loss: 1.0075\n",
            "Validation loss: 1.0176\n",
            "Training loss: 1.0075\n",
            "Validation loss: 1.0176\n",
            "Training loss: 1.0075\n",
            "Validation loss: 1.0176\n",
            "Training loss: 1.0075\n",
            "Validation loss: 1.0176\n",
            "Training loss: 1.0075\n",
            "Validation loss: 1.0176\n",
            "Training loss: 1.0075\n",
            "Validation loss: 1.0176\n",
            "Training loss: 1.0075\n",
            "Validation loss: 1.0176\n",
            "Training loss: 1.0075\n",
            "Validation loss: 1.0176\n",
            "Training loss: 1.0075\n",
            "Validation loss: 1.0176\n",
            "Training loss: 1.0075\n",
            "Validation loss: 1.0176\n",
            "Training loss: 1.0075\n",
            "Validation loss: 1.0176\n",
            "Training loss: 1.0075\n",
            "Validation loss: 1.0176\n",
            "Training loss: 1.0075\n",
            "Validation loss: 1.0176\n",
            "Training loss: 1.0075\n",
            "Validation loss: 1.0176\n",
            "Training loss: 1.0075\n",
            "Validation loss: 1.0176\n",
            "Training loss: 1.0075\n",
            "Validation loss: 1.0176\n",
            "Training loss: 1.0075\n",
            "Validation loss: 1.0176\n",
            "Training loss: 1.0075\n",
            "Validation loss: 1.0176\n",
            "Training loss: 1.0075\n",
            "Validation loss: 1.0176\n",
            "Training loss: 1.0075\n",
            "Validation loss: 1.0176\n",
            "Training loss: 1.0076\n",
            "Validation loss: 1.0176\n",
            "Training loss: 1.0076\n",
            "Validation loss: 1.0176\n",
            "Training loss: 1.0076\n",
            "Validation loss: 1.0176\n",
            "Training loss: 1.0076\n",
            "Validation loss: 1.0176\n",
            "Training loss: 1.0076\n",
            "Validation loss: 1.0176\n",
            "Training loss: 1.0076\n",
            "Validation loss: 1.0176\n",
            "Training loss: 1.0076\n",
            "Validation loss: 1.0176\n",
            "Training loss: 1.0076\n",
            "Validation loss: 1.0177\n",
            "Training loss: 1.0076\n",
            "Validation loss: 1.0177\n",
            "Training loss: 1.0076\n",
            "Validation loss: 1.0177\n",
            "Training loss: 1.0076\n",
            "Validation loss: 1.0177\n",
            "Training loss: 1.0076\n",
            "Validation loss: 1.0177\n",
            "Training loss: 1.0076\n",
            "Validation loss: 1.0177\n",
            "Training loss: 1.0076\n",
            "Validation loss: 1.0177\n",
            "Training loss: 1.0076\n",
            "Validation loss: 1.0177\n",
            "Training loss: 1.0076\n",
            "Validation loss: 1.0177\n",
            "Training loss: 1.0076\n",
            "Validation loss: 1.0177\n",
            "Training loss: 1.0076\n",
            "Validation loss: 1.0177\n",
            "Training loss: 1.0076\n",
            "Validation loss: 1.0177\n",
            "Training loss: 1.0076\n",
            "Validation loss: 1.0177\n",
            "Training loss: 1.0076\n",
            "Validation loss: 1.0177\n",
            "Training loss: 1.0076\n",
            "Validation loss: 1.0177\n",
            "Training loss: 1.0076\n",
            "Validation loss: 1.0177\n",
            "Training loss: 1.0076\n",
            "Validation loss: 1.0177\n",
            "Training loss: 1.0076\n",
            "Validation loss: 1.0177\n",
            "Training loss: 1.0076\n",
            "Validation loss: 1.0177\n",
            "Training loss: 1.0076\n",
            "Validation loss: 1.0177\n",
            "Training loss: 1.0076\n",
            "Validation loss: 1.0177\n",
            "Training loss: 1.0076\n",
            "Validation loss: 1.0177\n",
            "Training loss: 1.0077\n",
            "Validation loss: 1.0177\n",
            "Training loss: 1.0077\n",
            "Validation loss: 1.0177\n",
            "Training loss: 1.0077\n",
            "Validation loss: 1.0177\n",
            "Training loss: 1.0077\n",
            "Validation loss: 1.0178\n",
            "Training loss: 1.0077\n",
            "Validation loss: 1.0178\n",
            "Training loss: 1.0077\n",
            "Validation loss: 1.0178\n",
            "Training loss: 1.0077\n",
            "Validation loss: 1.0178\n",
            "Training loss: 1.0077\n",
            "Validation loss: 1.0178\n",
            "Training loss: 1.0077\n",
            "Validation loss: 1.0178\n",
            "Training loss: 1.0077\n",
            "Validation loss: 1.0178\n",
            "Training loss: 1.0077\n",
            "Validation loss: 1.0178\n",
            "Training loss: 1.0077\n",
            "Validation loss: 1.0178\n",
            "Training loss: 1.0077\n",
            "Validation loss: 1.0178\n",
            "Training loss: 1.0077\n",
            "Validation loss: 1.0178\n",
            "Training loss: 1.0077\n",
            "Validation loss: 1.0178\n",
            "Training loss: 1.0077\n",
            "Validation loss: 1.0178\n",
            "Training loss: 1.0077\n",
            "Validation loss: 1.0178\n",
            "Training loss: 1.0077\n",
            "Validation loss: 1.0178\n",
            "Training loss: 1.0077\n",
            "Validation loss: 1.0178\n",
            "Training loss: 1.0077\n",
            "Validation loss: 1.0178\n",
            "Training loss: 1.0077\n",
            "Validation loss: 1.0178\n",
            "Training loss: 1.0077\n",
            "Validation loss: 1.0178\n",
            "Training loss: 1.0077\n",
            "Validation loss: 1.0178\n",
            "Training loss: 1.0077\n",
            "Validation loss: 1.0178\n",
            "Training loss: 1.0077\n",
            "Validation loss: 1.0178\n",
            "Training loss: 1.0077\n",
            "Validation loss: 1.0178\n",
            "Training loss: 1.0077\n",
            "Validation loss: 1.0178\n",
            "Training loss: 1.0078\n",
            "Validation loss: 1.0178\n",
            "Training loss: 1.0078\n",
            "Validation loss: 1.0179\n",
            "Training loss: 1.0078\n",
            "Validation loss: 1.0179\n",
            "Training loss: 1.0078\n",
            "Validation loss: 1.0179\n",
            "Training loss: 1.0078\n",
            "Validation loss: 1.0179\n",
            "Training loss: 1.0078\n",
            "Validation loss: 1.0179\n",
            "Training loss: 1.0078\n",
            "Validation loss: 1.0179\n",
            "Training loss: 1.0078\n",
            "Validation loss: 1.0179\n",
            "Training loss: 1.0078\n",
            "Validation loss: 1.0179\n",
            "Training loss: 1.0078\n",
            "Validation loss: 1.0179\n",
            "Training loss: 1.0078\n",
            "Validation loss: 1.0179\n",
            "Training loss: 1.0078\n",
            "Validation loss: 1.0179\n",
            "Training loss: 1.0078\n",
            "Validation loss: 1.0179\n",
            "Training loss: 1.0078\n",
            "Validation loss: 1.0179\n",
            "Training loss: 1.0078\n",
            "Validation loss: 1.0179\n",
            "Training loss: 1.0078\n",
            "Validation loss: 1.0179\n",
            "Training loss: 1.0078\n",
            "Validation loss: 1.0179\n",
            "Training loss: 1.0078\n",
            "Validation loss: 1.0179\n",
            "Training loss: 1.0078\n",
            "Validation loss: 1.0179\n",
            "Training loss: 1.0078\n",
            "Validation loss: 1.0179\n",
            "Training loss: 1.0078\n",
            "Validation loss: 1.0179\n",
            "Training loss: 1.0078\n",
            "Validation loss: 1.0179\n",
            "Training loss: 1.0078\n",
            "Validation loss: 1.0179\n",
            "Training loss: 1.0078\n",
            "Validation loss: 1.0179\n",
            "Training loss: 1.0078\n",
            "Validation loss: 1.0179\n",
            "Training loss: 1.0078\n",
            "Validation loss: 1.0180\n",
            "Training loss: 1.0079\n",
            "Validation loss: 1.0180\n",
            "Training loss: 1.0079\n",
            "Validation loss: 1.0180\n",
            "Training loss: 1.0079\n",
            "Validation loss: 1.0180\n",
            "Training loss: 1.0079\n",
            "Validation loss: 1.0180\n",
            "Training loss: 1.0079\n",
            "Validation loss: 1.0180\n",
            "Training loss: 1.0079\n",
            "Validation loss: 1.0180\n",
            "Training loss: 1.0079\n",
            "Validation loss: 1.0180\n",
            "Training loss: 1.0079\n",
            "Validation loss: 1.0180\n",
            "Training loss: 1.0079\n",
            "Validation loss: 1.0180\n",
            "Training loss: 1.0079\n",
            "Validation loss: 1.0180\n",
            "Training loss: 1.0079\n",
            "Validation loss: 1.0180\n",
            "Training loss: 1.0079\n",
            "Validation loss: 1.0180\n",
            "Training loss: 1.0079\n",
            "Validation loss: 1.0180\n",
            "Training loss: 1.0079\n",
            "Validation loss: 1.0180\n",
            "Training loss: 1.0079\n",
            "Validation loss: 1.0180\n",
            "Training loss: 1.0079\n",
            "Validation loss: 1.0180\n",
            "Training loss: 1.0079\n",
            "Validation loss: 1.0180\n",
            "Training loss: 1.0079\n",
            "Validation loss: 1.0180\n",
            "Training loss: 1.0079\n",
            "Validation loss: 1.0180\n",
            "Training loss: 1.0079\n",
            "Validation loss: 1.0180\n",
            "Training loss: 1.0079\n",
            "Validation loss: 1.0180\n",
            "Training loss: 1.0079\n",
            "Validation loss: 1.0180\n",
            "Training loss: 1.0079\n",
            "Validation loss: 1.0181\n",
            "Training loss: 1.0079\n",
            "Validation loss: 1.0181\n",
            "Training loss: 1.0079\n",
            "Validation loss: 1.0181\n",
            "Training loss: 1.0080\n",
            "Validation loss: 1.0181\n",
            "Training loss: 1.0080\n",
            "Validation loss: 1.0181\n",
            "Training loss: 1.0080\n",
            "Validation loss: 1.0181\n",
            "Training loss: 1.0080\n",
            "Validation loss: 1.0181\n",
            "Training loss: 1.0080\n",
            "Validation loss: 1.0181\n",
            "Training loss: 1.0080\n",
            "Validation loss: 1.0181\n",
            "Training loss: 1.0080\n",
            "Validation loss: 1.0181\n",
            "Training loss: 1.0080\n",
            "Validation loss: 1.0181\n",
            "Training loss: 1.0080\n",
            "Validation loss: 1.0181\n",
            "Training loss: 1.0080\n",
            "Validation loss: 1.0181\n",
            "Training loss: 1.0080\n",
            "Validation loss: 1.0181\n",
            "Training loss: 1.0080\n",
            "Validation loss: 1.0181\n",
            "Training loss: 1.0080\n",
            "Validation loss: 1.0181\n",
            "Training loss: 1.0080\n",
            "Validation loss: 1.0181\n",
            "Training loss: 1.0080\n",
            "Validation loss: 1.0181\n",
            "Training loss: 1.0080\n",
            "Validation loss: 1.0181\n",
            "Training loss: 1.0080\n",
            "Validation loss: 1.0181\n",
            "Training loss: 1.0080\n",
            "Validation loss: 1.0181\n",
            "Training loss: 1.0080\n",
            "Validation loss: 1.0181\n",
            "Training loss: 1.0080\n",
            "Validation loss: 1.0182\n",
            "Training loss: 1.0080\n",
            "Validation loss: 1.0182\n",
            "Training loss: 1.0080\n",
            "Validation loss: 1.0182\n",
            "Training loss: 1.0080\n",
            "Validation loss: 1.0182\n",
            "Training loss: 1.0080\n",
            "Validation loss: 1.0182\n",
            "Training loss: 1.0081\n",
            "Validation loss: 1.0182\n",
            "Training loss: 1.0081\n",
            "Validation loss: 1.0182\n",
            "Training loss: 1.0081\n",
            "Validation loss: 1.0182\n",
            "Training loss: 1.0081\n",
            "Validation loss: 1.0182\n",
            "Training loss: 1.0081\n",
            "Validation loss: 1.0182\n",
            "Training loss: 1.0081\n",
            "Validation loss: 1.0182\n",
            "Training loss: 1.0081\n",
            "Validation loss: 1.0182\n",
            "Training loss: 1.0081\n",
            "Validation loss: 1.0182\n",
            "Training loss: 1.0081\n",
            "Validation loss: 1.0182\n",
            "Training loss: 1.0081\n",
            "Validation loss: 1.0182\n",
            "Training loss: 1.0081\n",
            "Validation loss: 1.0182\n",
            "Training loss: 1.0081\n",
            "Validation loss: 1.0182\n",
            "Training loss: 1.0081\n",
            "Validation loss: 1.0182\n",
            "Training loss: 1.0081\n",
            "Validation loss: 1.0182\n",
            "Training loss: 1.0081\n",
            "Validation loss: 1.0182\n",
            "Training loss: 1.0081\n",
            "Validation loss: 1.0182\n",
            "Training loss: 1.0081\n",
            "Validation loss: 1.0183\n",
            "Training loss: 1.0081\n",
            "Validation loss: 1.0183\n",
            "Training loss: 1.0081\n",
            "Validation loss: 1.0183\n",
            "Training loss: 1.0081\n",
            "Validation loss: 1.0183\n",
            "Training loss: 1.0081\n",
            "Validation loss: 1.0183\n",
            "Training loss: 1.0081\n",
            "Validation loss: 1.0183\n",
            "Training loss: 1.0081\n",
            "Validation loss: 1.0183\n",
            "Training loss: 1.0082\n",
            "Validation loss: 1.0183\n",
            "Training loss: 1.0082\n",
            "Validation loss: 1.0183\n",
            "Training loss: 1.0082\n",
            "Validation loss: 1.0183\n",
            "Training loss: 1.0082\n",
            "Validation loss: 1.0183\n",
            "Training loss: 1.0082\n",
            "Validation loss: 1.0183\n",
            "Training loss: 1.0082\n",
            "Validation loss: 1.0183\n",
            "Training loss: 1.0082\n",
            "Validation loss: 1.0183\n",
            "Training loss: 1.0082\n",
            "Validation loss: 1.0183\n",
            "Training loss: 1.0082\n",
            "Validation loss: 1.0183\n",
            "Training loss: 1.0082\n",
            "Validation loss: 1.0183\n",
            "Training loss: 1.0082\n",
            "Validation loss: 1.0183\n",
            "Training loss: 1.0082\n",
            "Validation loss: 1.0183\n",
            "Training loss: 1.0082\n",
            "Validation loss: 1.0183\n",
            "Training loss: 1.0082\n",
            "Validation loss: 1.0183\n",
            "Training loss: 1.0082\n",
            "Validation loss: 1.0184\n",
            "Training loss: 1.0082\n",
            "Validation loss: 1.0184\n",
            "Training loss: 1.0082\n",
            "Validation loss: 1.0184\n",
            "Training loss: 1.0082\n",
            "Validation loss: 1.0184\n",
            "Training loss: 1.0082\n",
            "Validation loss: 1.0184\n",
            "Training loss: 1.0082\n",
            "Validation loss: 1.0184\n",
            "Training loss: 1.0082\n",
            "Validation loss: 1.0184\n",
            "Training loss: 1.0082\n",
            "Validation loss: 1.0184\n",
            "Training loss: 1.0082\n",
            "Validation loss: 1.0184\n",
            "Training loss: 1.0083\n",
            "Validation loss: 1.0184\n",
            "Training loss: 1.0083\n",
            "Validation loss: 1.0184\n",
            "Training loss: 1.0083\n",
            "Validation loss: 1.0184\n",
            "Training loss: 1.0083\n",
            "Validation loss: 1.0184\n",
            "Training loss: 1.0083\n",
            "Validation loss: 1.0184\n",
            "Training loss: 1.0083\n",
            "Validation loss: 1.0184\n",
            "Training loss: 1.0083\n",
            "Validation loss: 1.0184\n",
            "Training loss: 1.0083\n",
            "Validation loss: 1.0184\n",
            "Training loss: 1.0083\n",
            "Validation loss: 1.0184\n",
            "Training loss: 1.0083\n",
            "Validation loss: 1.0184\n",
            "Training loss: 1.0083\n",
            "Validation loss: 1.0184\n",
            "Training loss: 1.0083\n",
            "Validation loss: 1.0185\n",
            "Training loss: 1.0083\n",
            "Validation loss: 1.0185\n",
            "Training loss: 1.0083\n",
            "Validation loss: 1.0185\n",
            "Training loss: 1.0083\n",
            "Validation loss: 1.0185\n",
            "Training loss: 1.0083\n",
            "Validation loss: 1.0185\n",
            "Training loss: 1.0083\n",
            "Validation loss: 1.0185\n",
            "Training loss: 1.0083\n",
            "Validation loss: 1.0185\n",
            "Training loss: 1.0083\n",
            "Validation loss: 1.0185\n",
            "Training loss: 1.0083\n",
            "Validation loss: 1.0185\n",
            "Training loss: 1.0083\n",
            "Validation loss: 1.0185\n",
            "Training loss: 1.0084\n",
            "Validation loss: 1.0185\n",
            "Training loss: 1.0084\n",
            "Validation loss: 1.0185\n",
            "Training loss: 1.0084\n",
            "Validation loss: 1.0185\n",
            "Training loss: 1.0084\n",
            "Validation loss: 1.0185\n",
            "Training loss: 1.0084\n",
            "Validation loss: 1.0185\n",
            "Training loss: 1.0084\n",
            "Validation loss: 1.0185\n",
            "Training loss: 1.0084\n",
            "Validation loss: 1.0185\n",
            "Training loss: 1.0084\n",
            "Validation loss: 1.0185\n",
            "Training loss: 1.0084\n",
            "Validation loss: 1.0185\n",
            "Training loss: 1.0084\n",
            "Validation loss: 1.0185\n",
            "Training loss: 1.0084\n",
            "Validation loss: 1.0186\n",
            "Training loss: 1.0084\n",
            "Validation loss: 1.0186\n",
            "Training loss: 1.0084\n",
            "Validation loss: 1.0186\n",
            "Training loss: 1.0084\n",
            "Validation loss: 1.0186\n",
            "Training loss: 1.0084\n",
            "Validation loss: 1.0186\n",
            "Training loss: 1.0084\n",
            "Validation loss: 1.0186\n",
            "Training loss: 1.0084\n",
            "Validation loss: 1.0186\n",
            "Training loss: 1.0084\n",
            "Validation loss: 1.0186\n",
            "Training loss: 1.0084\n",
            "Validation loss: 1.0186\n",
            "Training loss: 1.0084\n",
            "Validation loss: 1.0186\n",
            "Training loss: 1.0084\n",
            "Validation loss: 1.0186\n",
            "Training loss: 1.0085\n",
            "Validation loss: 1.0186\n",
            "Training loss: 1.0085\n",
            "Validation loss: 1.0186\n",
            "Training loss: 1.0085\n",
            "Validation loss: 1.0186\n",
            "Training loss: 1.0085\n",
            "Validation loss: 1.0186\n",
            "Training loss: 1.0085\n",
            "Validation loss: 1.0186\n",
            "Training loss: 1.0085\n",
            "Validation loss: 1.0186\n",
            "Training loss: 1.0085\n",
            "Validation loss: 1.0186\n",
            "Training loss: 1.0085\n",
            "Validation loss: 1.0186\n",
            "Training loss: 1.0085\n",
            "Validation loss: 1.0187\n",
            "Training loss: 1.0085\n",
            "Validation loss: 1.0187\n",
            "Training loss: 1.0085\n",
            "Validation loss: 1.0187\n",
            "Training loss: 1.0085\n",
            "Validation loss: 1.0187\n",
            "Training loss: 1.0085\n",
            "Validation loss: 1.0187\n",
            "Training loss: 1.0085\n",
            "Validation loss: 1.0187\n",
            "Training loss: 1.0085\n",
            "Validation loss: 1.0187\n",
            "Training loss: 1.0085\n",
            "Validation loss: 1.0187\n",
            "Training loss: 1.0085\n",
            "Validation loss: 1.0187\n",
            "Training loss: 1.0085\n",
            "Validation loss: 1.0187\n",
            "Training loss: 1.0085\n",
            "Validation loss: 1.0187\n",
            "Training loss: 1.0085\n",
            "Validation loss: 1.0187\n",
            "Training loss: 1.0085\n",
            "Validation loss: 1.0187\n",
            "Training loss: 1.0086\n",
            "Validation loss: 1.0187\n",
            "Training loss: 1.0086\n",
            "Validation loss: 1.0187\n",
            "Training loss: 1.0086\n",
            "Validation loss: 1.0187\n",
            "Training loss: 1.0086\n",
            "Validation loss: 1.0187\n",
            "Training loss: 1.0086\n",
            "Validation loss: 1.0187\n",
            "Training loss: 1.0086\n",
            "Validation loss: 1.0188\n",
            "Training loss: 1.0086\n",
            "Validation loss: 1.0188\n",
            "Training loss: 1.0086\n",
            "Validation loss: 1.0188\n",
            "Training loss: 1.0086\n",
            "Validation loss: 1.0188\n",
            "Training loss: 1.0086\n",
            "Validation loss: 1.0188\n",
            "Training loss: 1.0086\n",
            "Validation loss: 1.0188\n",
            "Training loss: 1.0086\n",
            "Validation loss: 1.0188\n",
            "Training loss: 1.0086\n",
            "Validation loss: 1.0188\n",
            "Training loss: 1.0086\n",
            "Validation loss: 1.0188\n",
            "Training loss: 1.0086\n",
            "Validation loss: 1.0188\n",
            "Training loss: 1.0086\n",
            "Validation loss: 1.0188\n",
            "Training loss: 1.0086\n",
            "Validation loss: 1.0188\n",
            "Training loss: 1.0086\n",
            "Validation loss: 1.0188\n",
            "Training loss: 1.0086\n",
            "Validation loss: 1.0188\n",
            "Training loss: 1.0087\n",
            "Validation loss: 1.0188\n",
            "Training loss: 1.0087\n",
            "Validation loss: 1.0188\n",
            "Training loss: 1.0087\n",
            "Validation loss: 1.0188\n",
            "Training loss: 1.0087\n",
            "Validation loss: 1.0188\n",
            "Training loss: 1.0087\n",
            "Validation loss: 1.0189\n",
            "Training loss: 1.0087\n",
            "Validation loss: 1.0189\n",
            "Training loss: 1.0087\n",
            "Validation loss: 1.0189\n",
            "Training loss: 1.0087\n",
            "Validation loss: 1.0189\n",
            "Training loss: 1.0087\n",
            "Validation loss: 1.0189\n",
            "Training loss: 1.0087\n",
            "Validation loss: 1.0189\n",
            "Training loss: 1.0087\n",
            "Validation loss: 1.0189\n",
            "Training loss: 1.0087\n",
            "Validation loss: 1.0189\n",
            "Training loss: 1.0087\n",
            "Validation loss: 1.0189\n",
            "Training loss: 1.0087\n",
            "Validation loss: 1.0189\n",
            "Training loss: 1.0087\n",
            "Validation loss: 1.0189\n",
            "Training loss: 1.0087\n",
            "Validation loss: 1.0189\n",
            "Training loss: 1.0087\n",
            "Validation loss: 1.0189\n",
            "Training loss: 1.0087\n",
            "Validation loss: 1.0189\n",
            "Training loss: 1.0087\n",
            "Validation loss: 1.0189\n",
            "Training loss: 1.0087\n",
            "Validation loss: 1.0189\n",
            "Training loss: 1.0088\n",
            "Validation loss: 1.0189\n",
            "Training loss: 1.0088\n",
            "Validation loss: 1.0189\n",
            "Training loss: 1.0088\n",
            "Validation loss: 1.0190\n",
            "Training loss: 1.0088\n",
            "Validation loss: 1.0190\n",
            "Training loss: 1.0088\n",
            "Validation loss: 1.0190\n",
            "Training loss: 1.0088\n",
            "Validation loss: 1.0190\n",
            "Training loss: 1.0088\n",
            "Validation loss: 1.0190\n",
            "Training loss: 1.0088\n",
            "Validation loss: 1.0190\n",
            "Training loss: 1.0088\n",
            "Validation loss: 1.0190\n",
            "Training loss: 1.0088\n",
            "Validation loss: 1.0190\n",
            "Training loss: 1.0088\n",
            "Validation loss: 1.0190\n",
            "Training loss: 1.0088\n",
            "Validation loss: 1.0190\n",
            "Training loss: 1.0088\n",
            "Validation loss: 1.0190\n",
            "Training loss: 1.0088\n",
            "Validation loss: 1.0190\n",
            "Training loss: 1.0088\n",
            "Validation loss: 1.0190\n",
            "Training loss: 1.0088\n",
            "Validation loss: 1.0190\n",
            "Training loss: 1.0088\n",
            "Validation loss: 1.0190\n",
            "Training loss: 1.0088\n",
            "Validation loss: 1.0190\n",
            "Training loss: 1.0089\n",
            "Validation loss: 1.0190\n",
            "Training loss: 1.0089\n",
            "Validation loss: 1.0191\n",
            "Training loss: 1.0089\n",
            "Validation loss: 1.0191\n",
            "Training loss: 1.0089\n",
            "Validation loss: 1.0191\n",
            "Training loss: 1.0089\n",
            "Validation loss: 1.0191\n",
            "Training loss: 1.0089\n",
            "Validation loss: 1.0191\n",
            "Training loss: 1.0089\n",
            "Validation loss: 1.0191\n",
            "Training loss: 1.0089\n",
            "Validation loss: 1.0191\n",
            "Training loss: 1.0089\n",
            "Validation loss: 1.0191\n",
            "Training loss: 1.0089\n",
            "Validation loss: 1.0191\n",
            "Training loss: 1.0089\n",
            "Validation loss: 1.0191\n",
            "Training loss: 1.0089\n",
            "Validation loss: 1.0191\n",
            "Training loss: 1.0089\n",
            "Validation loss: 1.0191\n",
            "Training loss: 1.0089\n",
            "Validation loss: 1.0191\n",
            "Training loss: 1.0089\n",
            "Validation loss: 1.0191\n",
            "Training loss: 1.0089\n",
            "Validation loss: 1.0191\n",
            "Training loss: 1.0089\n",
            "Validation loss: 1.0191\n",
            "Training loss: 1.0089\n",
            "Validation loss: 1.0191\n",
            "Training loss: 1.0090\n",
            "Validation loss: 1.0192\n",
            "Training loss: 1.0090\n",
            "Validation loss: 1.0192\n",
            "Training loss: 1.0090\n",
            "Validation loss: 1.0192\n",
            "Training loss: 1.0090\n",
            "Validation loss: 1.0192\n",
            "Training loss: 1.0090\n",
            "Validation loss: 1.0192\n",
            "Training loss: 1.0090\n",
            "Validation loss: 1.0192\n",
            "Training loss: 1.0090\n",
            "Validation loss: 1.0192\n",
            "Training loss: 1.0090\n",
            "Validation loss: 1.0192\n",
            "Training loss: 1.0090\n",
            "Validation loss: 1.0192\n",
            "Training loss: 1.0090\n",
            "Validation loss: 1.0192\n",
            "Training loss: 1.0090\n",
            "Validation loss: 1.0192\n",
            "Training loss: 1.0090\n",
            "Validation loss: 1.0192\n",
            "Training loss: 1.0090\n",
            "Validation loss: 1.0192\n",
            "Training loss: 1.0090\n",
            "Validation loss: 1.0192\n",
            "Training loss: 1.0090\n",
            "Validation loss: 1.0192\n",
            "Training loss: 1.0090\n",
            "Validation loss: 1.0192\n",
            "Training loss: 1.0090\n",
            "Validation loss: 1.0193\n",
            "Training loss: 1.0090\n",
            "Validation loss: 1.0193\n",
            "Training loss: 1.0091\n",
            "Validation loss: 1.0193\n",
            "Training loss: 1.0091\n",
            "Validation loss: 1.0193\n",
            "Training loss: 1.0091\n",
            "Validation loss: 1.0193\n",
            "Training loss: 1.0091\n",
            "Validation loss: 1.0193\n",
            "Training loss: 1.0091\n",
            "Validation loss: 1.0193\n",
            "Training loss: 1.0091\n",
            "Validation loss: 1.0193\n",
            "Training loss: 1.0091\n",
            "Validation loss: 1.0193\n",
            "Training loss: 1.0091\n",
            "Validation loss: 1.0193\n",
            "Training loss: 1.0091\n",
            "Validation loss: 1.0193\n",
            "Training loss: 1.0091\n",
            "Validation loss: 1.0193\n",
            "Training loss: 1.0091\n",
            "Validation loss: 1.0193\n",
            "Training loss: 1.0091\n",
            "Validation loss: 1.0193\n",
            "Training loss: 1.0091\n",
            "Validation loss: 1.0193\n",
            "Training loss: 1.0091\n",
            "Validation loss: 1.0193\n",
            "Training loss: 1.0091\n",
            "Validation loss: 1.0193\n",
            "Training loss: 1.0091\n",
            "Validation loss: 1.0194\n",
            "Training loss: 1.0091\n",
            "Validation loss: 1.0194\n",
            "Training loss: 1.0091\n",
            "Validation loss: 1.0194\n",
            "Training loss: 1.0092\n",
            "Validation loss: 1.0194\n",
            "Training loss: 1.0092\n",
            "Validation loss: 1.0194\n",
            "Training loss: 1.0092\n",
            "Validation loss: 1.0194\n",
            "Training loss: 1.0092\n",
            "Validation loss: 1.0194\n",
            "Training loss: 1.0092\n",
            "Validation loss: 1.0194\n",
            "Training loss: 1.0092\n",
            "Validation loss: 1.0194\n",
            "Training loss: 1.0092\n",
            "Validation loss: 1.0194\n",
            "Training loss: 1.0092\n",
            "Validation loss: 1.0194\n",
            "Training loss: 1.0092\n",
            "Validation loss: 1.0194\n",
            "Training loss: 1.0092\n",
            "Validation loss: 1.0194\n",
            "Training loss: 1.0092\n",
            "Validation loss: 1.0194\n",
            "Training loss: 1.0092\n",
            "Validation loss: 1.0194\n",
            "Training loss: 1.0092\n",
            "Validation loss: 1.0195\n",
            "Training loss: 1.0092\n",
            "Validation loss: 1.0195\n",
            "Training loss: 1.0092\n",
            "Validation loss: 1.0195\n",
            "Training loss: 1.0092\n",
            "Validation loss: 1.0195\n",
            "Training loss: 1.0092\n",
            "Validation loss: 1.0195\n",
            "Training loss: 1.0093\n",
            "Validation loss: 1.0195\n",
            "Training loss: 1.0093\n",
            "Validation loss: 1.0195\n",
            "Training loss: 1.0093\n",
            "Validation loss: 1.0195\n",
            "Training loss: 1.0093\n",
            "Validation loss: 1.0195\n",
            "Training loss: 1.0093\n",
            "Validation loss: 1.0195\n",
            "Training loss: 1.0093\n",
            "Validation loss: 1.0195\n",
            "Training loss: 1.0093\n",
            "Validation loss: 1.0195\n",
            "Training loss: 1.0093\n",
            "Validation loss: 1.0195\n",
            "Training loss: 1.0093\n",
            "Validation loss: 1.0195\n",
            "Training loss: 1.0093\n",
            "Validation loss: 1.0195\n",
            "Training loss: 1.0093\n",
            "Validation loss: 1.0195\n",
            "Training loss: 1.0093\n",
            "Validation loss: 1.0196\n",
            "Training loss: 1.0093\n",
            "Validation loss: 1.0196\n",
            "Training loss: 1.0093\n",
            "Validation loss: 1.0196\n",
            "Training loss: 1.0093\n",
            "Validation loss: 1.0196\n",
            "Training loss: 1.0093\n",
            "Validation loss: 1.0196\n",
            "Training loss: 1.0094\n",
            "Validation loss: 1.0196\n",
            "Training loss: 1.0094\n",
            "Validation loss: 1.0196\n",
            "Training loss: 1.0094\n",
            "Validation loss: 1.0196\n",
            "Training loss: 1.0094\n",
            "Validation loss: 1.0196\n",
            "Training loss: 1.0094\n",
            "Validation loss: 1.0196\n",
            "Training loss: 1.0094\n",
            "Validation loss: 1.0196\n",
            "Training loss: 1.0094\n",
            "Validation loss: 1.0196\n",
            "Training loss: 1.0094\n",
            "Validation loss: 1.0196\n",
            "Training loss: 1.0094\n",
            "Validation loss: 1.0196\n",
            "Training loss: 1.0094\n",
            "Validation loss: 1.0196\n",
            "Training loss: 1.0094\n",
            "Validation loss: 1.0197\n",
            "Training loss: 1.0094\n",
            "Validation loss: 1.0197\n",
            "Training loss: 1.0094\n",
            "Validation loss: 1.0197\n",
            "Training loss: 1.0094\n",
            "Validation loss: 1.0197\n",
            "Training loss: 1.0094\n",
            "Validation loss: 1.0197\n",
            "Training loss: 1.0094\n",
            "Validation loss: 1.0197\n",
            "Training loss: 1.0094\n",
            "Validation loss: 1.0197\n",
            "Training loss: 1.0095\n",
            "Validation loss: 1.0197\n",
            "Training loss: 1.0095\n",
            "Validation loss: 1.0197\n",
            "Training loss: 1.0095\n",
            "Validation loss: 1.0197\n",
            "Training loss: 1.0095\n",
            "Validation loss: 1.0197\n",
            "Training loss: 1.0095\n",
            "Validation loss: 1.0197\n",
            "Training loss: 1.0095\n",
            "Validation loss: 1.0197\n",
            "Training loss: 1.0095\n",
            "Validation loss: 1.0197\n",
            "Training loss: 1.0095\n",
            "Validation loss: 1.0197\n",
            "Training loss: 1.0095\n",
            "Validation loss: 1.0198\n",
            "Training loss: 1.0095\n",
            "Validation loss: 1.0198\n",
            "Training loss: 1.0095\n",
            "Validation loss: 1.0198\n",
            "Training loss: 1.0095\n",
            "Validation loss: 1.0198\n",
            "Training loss: 1.0095\n",
            "Validation loss: 1.0198\n",
            "Training loss: 1.0095\n",
            "Validation loss: 1.0198\n",
            "Training loss: 1.0095\n",
            "Validation loss: 1.0198\n",
            "Training loss: 1.0095\n",
            "Validation loss: 1.0198\n",
            "Training loss: 1.0096\n",
            "Validation loss: 1.0198\n",
            "Training loss: 1.0096\n",
            "Validation loss: 1.0198\n",
            "Training loss: 1.0096\n",
            "Validation loss: 1.0198\n",
            "Training loss: 1.0096\n",
            "Validation loss: 1.0198\n",
            "Training loss: 1.0096\n",
            "Validation loss: 1.0198\n",
            "Training loss: 1.0096\n",
            "Validation loss: 1.0198\n",
            "Training loss: 1.0096\n",
            "Validation loss: 1.0198\n",
            "Training loss: 1.0096\n",
            "Validation loss: 1.0199\n",
            "Training loss: 1.0096\n",
            "Validation loss: 1.0199\n",
            "Training loss: 1.0096\n",
            "Validation loss: 1.0199\n",
            "Training loss: 1.0096\n",
            "Validation loss: 1.0199\n",
            "Training loss: 1.0096\n",
            "Validation loss: 1.0199\n",
            "Training loss: 1.0096\n",
            "Validation loss: 1.0199\n",
            "Training loss: 1.0096\n",
            "Validation loss: 1.0199\n",
            "Training loss: 1.0096\n",
            "Validation loss: 1.0199\n",
            "Training loss: 1.0097\n",
            "Validation loss: 1.0199\n",
            "Training loss: 1.0097\n",
            "Validation loss: 1.0199\n",
            "Training loss: 1.0097\n",
            "Validation loss: 1.0199\n",
            "Training loss: 1.0097\n",
            "Validation loss: 1.0199\n",
            "Training loss: 1.0097\n",
            "Validation loss: 1.0199\n",
            "Training loss: 1.0097\n",
            "Validation loss: 1.0199\n",
            "Training loss: 1.0097\n",
            "Validation loss: 1.0200\n",
            "Training loss: 1.0097\n",
            "Validation loss: 1.0200\n",
            "Training loss: 1.0097\n",
            "Validation loss: 1.0200\n",
            "Training loss: 1.0097\n",
            "Validation loss: 1.0200\n",
            "Training loss: 1.0097\n",
            "Validation loss: 1.0200\n",
            "Training loss: 1.0097\n",
            "Validation loss: 1.0200\n",
            "Training loss: 1.0097\n",
            "Validation loss: 1.0200\n",
            "Training loss: 1.0097\n",
            "Validation loss: 1.0200\n",
            "Training loss: 1.0097\n",
            "Validation loss: 1.0200\n",
            "Training loss: 1.0097\n",
            "Validation loss: 1.0200\n",
            "Training loss: 1.0098\n",
            "Validation loss: 1.0200\n",
            "Training loss: 1.0098\n",
            "Validation loss: 1.0200\n",
            "Training loss: 1.0098\n",
            "Validation loss: 1.0200\n",
            "Training loss: 1.0098\n",
            "Validation loss: 1.0200\n",
            "Training loss: 1.0098\n",
            "Validation loss: 1.0201\n",
            "Training loss: 1.0098\n",
            "Validation loss: 1.0201\n",
            "Training loss: 1.0098\n",
            "Validation loss: 1.0201\n",
            "Training loss: 1.0098\n",
            "Validation loss: 1.0201\n",
            "Training loss: 1.0098\n",
            "Validation loss: 1.0201\n",
            "Training loss: 1.0098\n",
            "Validation loss: 1.0201\n",
            "Training loss: 1.0098\n",
            "Validation loss: 1.0201\n",
            "Training loss: 1.0098\n",
            "Validation loss: 1.0201\n",
            "Training loss: 1.0098\n",
            "Validation loss: 1.0201\n",
            "Training loss: 1.0098\n",
            "Validation loss: 1.0201\n",
            "Training loss: 1.0098\n",
            "Validation loss: 1.0201\n",
            "Training loss: 1.0099\n",
            "Validation loss: 1.0201\n",
            "Training loss: 1.0099\n",
            "Validation loss: 1.0201\n",
            "Training loss: 1.0099\n",
            "Validation loss: 1.0201\n",
            "Training loss: 1.0099\n",
            "Validation loss: 1.0202\n",
            "Training loss: 1.0099\n",
            "Validation loss: 1.0202\n",
            "Training loss: 1.0099\n",
            "Validation loss: 1.0202\n",
            "Training loss: 1.0099\n",
            "Validation loss: 1.0202\n",
            "Training loss: 1.0099\n",
            "Validation loss: 1.0202\n",
            "Training loss: 1.0099\n",
            "Validation loss: 1.0202\n",
            "Training loss: 1.0099\n",
            "Validation loss: 1.0202\n",
            "Training loss: 1.0099\n",
            "Validation loss: 1.0202\n",
            "Training loss: 1.0099\n",
            "Validation loss: 1.0202\n",
            "Training loss: 1.0099\n",
            "Validation loss: 1.0202\n",
            "Training loss: 1.0099\n",
            "Validation loss: 1.0202\n",
            "Training loss: 1.0100\n",
            "Validation loss: 1.0202\n",
            "Training loss: 1.0100\n",
            "Validation loss: 1.0202\n",
            "Training loss: 1.0100\n",
            "Validation loss: 1.0202\n",
            "Training loss: 1.0100\n",
            "Validation loss: 1.0203\n",
            "Training loss: 1.0100\n",
            "Validation loss: 1.0203\n",
            "Training loss: 1.0100\n",
            "Validation loss: 1.0203\n",
            "Training loss: 1.0100\n",
            "Validation loss: 1.0203\n",
            "Training loss: 1.0100\n",
            "Validation loss: 1.0203\n",
            "Training loss: 1.0100\n",
            "Validation loss: 1.0203\n",
            "Training loss: 1.0100\n",
            "Validation loss: 1.0203\n",
            "Training loss: 1.0100\n",
            "Validation loss: 1.0203\n",
            "Training loss: 1.0100\n",
            "Validation loss: 1.0203\n",
            "Training loss: 1.0100\n",
            "Validation loss: 1.0203\n",
            "Training loss: 1.0100\n",
            "Validation loss: 1.0203\n",
            "Training loss: 1.0100\n",
            "Validation loss: 1.0203\n",
            "Training loss: 1.0101\n",
            "Validation loss: 1.0203\n",
            "Training loss: 1.0101\n",
            "Validation loss: 1.0204\n",
            "Training loss: 1.0101\n",
            "Validation loss: 1.0204\n",
            "Training loss: 1.0101\n",
            "Validation loss: 1.0204\n",
            "Training loss: 1.0101\n",
            "Validation loss: 1.0204\n",
            "Training loss: 1.0101\n",
            "Validation loss: 1.0204\n",
            "Training loss: 1.0101\n",
            "Validation loss: 1.0204\n",
            "Training loss: 1.0101\n",
            "Validation loss: 1.0204\n",
            "Training loss: 1.0101\n",
            "Validation loss: 1.0204\n",
            "Training loss: 1.0101\n",
            "Validation loss: 1.0204\n",
            "Training loss: 1.0101\n",
            "Validation loss: 1.0204\n",
            "Training loss: 1.0101\n",
            "Validation loss: 1.0204\n",
            "Training loss: 1.0101\n",
            "Validation loss: 1.0204\n",
            "Training loss: 1.0101\n",
            "Validation loss: 1.0204\n",
            "Training loss: 1.0102\n",
            "Validation loss: 1.0205\n",
            "Training loss: 1.0102\n",
            "Validation loss: 1.0205\n",
            "Training loss: 1.0102\n",
            "Validation loss: 1.0205\n",
            "Training loss: 1.0102\n",
            "Validation loss: 1.0205\n",
            "Training loss: 1.0102\n",
            "Validation loss: 1.0205\n",
            "Training loss: 1.0102\n",
            "Validation loss: 1.0205\n",
            "Training loss: 1.0102\n",
            "Validation loss: 1.0205\n",
            "Training loss: 1.0102\n",
            "Validation loss: 1.0205\n",
            "Training loss: 1.0102\n",
            "Validation loss: 1.0205\n",
            "Training loss: 1.0102\n",
            "Validation loss: 1.0205\n",
            "Training loss: 1.0102\n",
            "Validation loss: 1.0205\n",
            "Training loss: 1.0102\n",
            "Validation loss: 1.0205\n",
            "Training loss: 1.0102\n",
            "Validation loss: 1.0205\n",
            "Training loss: 1.0102\n",
            "Validation loss: 1.0206\n",
            "Training loss: 1.0103\n",
            "Validation loss: 1.0206\n",
            "Training loss: 1.0103\n",
            "Validation loss: 1.0206\n",
            "Training loss: 1.0103\n",
            "Validation loss: 1.0206\n",
            "Training loss: 1.0103\n",
            "Validation loss: 1.0206\n",
            "Training loss: 1.0103\n",
            "Validation loss: 1.0206\n",
            "Training loss: 1.0103\n",
            "Validation loss: 1.0206\n",
            "Training loss: 1.0103\n",
            "Validation loss: 1.0206\n",
            "Training loss: 1.0103\n",
            "Validation loss: 1.0206\n",
            "Training loss: 1.0103\n",
            "Validation loss: 1.0206\n",
            "Training loss: 1.0103\n",
            "Validation loss: 1.0206\n",
            "Training loss: 1.0103\n",
            "Validation loss: 1.0206\n",
            "Training loss: 1.0103\n",
            "Validation loss: 1.0206\n",
            "Training loss: 1.0103\n",
            "Validation loss: 1.0207\n",
            "Training loss: 1.0103\n",
            "Validation loss: 1.0207\n",
            "Training loss: 1.0104\n",
            "Validation loss: 1.0207\n",
            "Training loss: 1.0104\n",
            "Validation loss: 1.0207\n",
            "Training loss: 1.0104\n",
            "Validation loss: 1.0207\n",
            "Training loss: 1.0104\n",
            "Validation loss: 1.0207\n",
            "Training loss: 1.0104\n",
            "Validation loss: 1.0207\n",
            "Training loss: 1.0104\n",
            "Validation loss: 1.0207\n",
            "Training loss: 1.0104\n",
            "Validation loss: 1.0207\n",
            "Training loss: 1.0104\n",
            "Validation loss: 1.0207\n",
            "Training loss: 1.0104\n",
            "Validation loss: 1.0207\n",
            "Training loss: 1.0104\n",
            "Validation loss: 1.0207\n",
            "Training loss: 1.0104\n",
            "Validation loss: 1.0207\n",
            "Training loss: 1.0104\n",
            "Validation loss: 1.0208\n",
            "Training loss: 1.0104\n",
            "Validation loss: 1.0208\n",
            "Training loss: 1.0104\n",
            "Validation loss: 1.0208\n",
            "Training loss: 1.0105\n",
            "Validation loss: 1.0208\n",
            "Training loss: 1.0105\n",
            "Validation loss: 1.0208\n",
            "Training loss: 1.0105\n",
            "Validation loss: 1.0208\n",
            "Training loss: 1.0105\n",
            "Validation loss: 1.0208\n",
            "Training loss: 1.0105\n",
            "Validation loss: 1.0208\n",
            "Training loss: 1.0105\n",
            "Validation loss: 1.0208\n",
            "Training loss: 1.0105\n",
            "Validation loss: 1.0208\n",
            "Training loss: 1.0105\n",
            "Validation loss: 1.0208\n",
            "Training loss: 1.0105\n",
            "Validation loss: 1.0208\n",
            "Training loss: 1.0105\n",
            "Validation loss: 1.0209\n",
            "Training loss: 1.0105\n",
            "Validation loss: 1.0209\n",
            "Training loss: 1.0105\n",
            "Validation loss: 1.0209\n",
            "Training loss: 1.0105\n",
            "Validation loss: 1.0209\n",
            "Training loss: 1.0106\n",
            "Validation loss: 1.0209\n",
            "Training loss: 1.0106\n",
            "Validation loss: 1.0209\n",
            "Training loss: 1.0106\n",
            "Validation loss: 1.0209\n",
            "Training loss: 1.0106\n",
            "Validation loss: 1.0209\n",
            "Training loss: 1.0106\n",
            "Validation loss: 1.0209\n",
            "Training loss: 1.0106\n",
            "Validation loss: 1.0209\n",
            "Training loss: 1.0106\n",
            "Validation loss: 1.0209\n",
            "Training loss: 1.0106\n",
            "Validation loss: 1.0209\n",
            "Training loss: 1.0106\n",
            "Validation loss: 1.0209\n",
            "Training loss: 1.0106\n",
            "Validation loss: 1.0210\n",
            "Training loss: 1.0106\n",
            "Validation loss: 1.0210\n",
            "Training loss: 1.0106\n",
            "Validation loss: 1.0210\n",
            "Training loss: 1.0106\n",
            "Validation loss: 1.0210\n",
            "Training loss: 1.0107\n",
            "Validation loss: 1.0210\n",
            "Training loss: 1.0107\n",
            "Validation loss: 1.0210\n",
            "Training loss: 1.0107\n",
            "Validation loss: 1.0210\n",
            "Training loss: 1.0107\n",
            "Validation loss: 1.0210\n",
            "Training loss: 1.0107\n",
            "Validation loss: 1.0210\n",
            "Training loss: 1.0107\n",
            "Validation loss: 1.0210\n",
            "Training loss: 1.0107\n",
            "Validation loss: 1.0210\n",
            "Training loss: 1.0107\n",
            "Validation loss: 1.0210\n",
            "Training loss: 1.0107\n",
            "Validation loss: 1.0211\n",
            "Training loss: 1.0107\n",
            "Validation loss: 1.0211\n",
            "Training loss: 1.0107\n",
            "Validation loss: 1.0211\n",
            "Training loss: 1.0107\n",
            "Validation loss: 1.0211\n",
            "Training loss: 1.0107\n",
            "Validation loss: 1.0211\n",
            "Training loss: 1.0108\n",
            "Validation loss: 1.0211\n",
            "Training loss: 1.0108\n",
            "Validation loss: 1.0211\n",
            "Training loss: 1.0108\n",
            "Validation loss: 1.0211\n",
            "Training loss: 1.0108\n",
            "Validation loss: 1.0211\n",
            "Training loss: 1.0108\n",
            "Validation loss: 1.0211\n",
            "Training loss: 1.0108\n",
            "Validation loss: 1.0211\n",
            "Training loss: 1.0108\n",
            "Validation loss: 1.0211\n",
            "Training loss: 1.0108\n",
            "Validation loss: 1.0212\n",
            "Training loss: 1.0108\n",
            "Validation loss: 1.0212\n",
            "Training loss: 1.0108\n",
            "Validation loss: 1.0212\n",
            "Training loss: 1.0108\n",
            "Validation loss: 1.0212\n",
            "Training loss: 1.0108\n",
            "Validation loss: 1.0212\n",
            "Training loss: 1.0108\n",
            "Validation loss: 1.0212\n",
            "Training loss: 1.0109\n",
            "Validation loss: 1.0212\n",
            "Training loss: 1.0109\n",
            "Validation loss: 1.0212\n",
            "Training loss: 1.0109\n",
            "Validation loss: 1.0212\n",
            "Training loss: 1.0109\n",
            "Validation loss: 1.0212\n",
            "Training loss: 1.0109\n",
            "Validation loss: 1.0212\n",
            "Training loss: 1.0109\n",
            "Validation loss: 1.0212\n",
            "Training loss: 1.0109\n",
            "Validation loss: 1.0213\n",
            "Training loss: 1.0109\n",
            "Validation loss: 1.0213\n",
            "Training loss: 1.0109\n",
            "Validation loss: 1.0213\n",
            "Training loss: 1.0109\n",
            "Validation loss: 1.0213\n",
            "Training loss: 1.0109\n",
            "Validation loss: 1.0213\n",
            "Training loss: 1.0109\n",
            "Validation loss: 1.0213\n",
            "Training loss: 1.0110\n",
            "Validation loss: 1.0213\n",
            "Training loss: 1.0110\n",
            "Validation loss: 1.0213\n",
            "Training loss: 1.0110\n",
            "Validation loss: 1.0213\n",
            "Training loss: 1.0110\n",
            "Validation loss: 1.0213\n",
            "Training loss: 1.0110\n",
            "Validation loss: 1.0213\n",
            "Training loss: 1.0110\n",
            "Validation loss: 1.0214\n",
            "Training loss: 1.0110\n",
            "Validation loss: 1.0214\n",
            "Training loss: 1.0110\n",
            "Validation loss: 1.0214\n",
            "Training loss: 1.0110\n",
            "Validation loss: 1.0214\n",
            "Training loss: 1.0110\n",
            "Validation loss: 1.0214\n",
            "Training loss: 1.0110\n",
            "Validation loss: 1.0214\n",
            "Training loss: 1.0110\n",
            "Validation loss: 1.0214\n",
            "Training loss: 1.0110\n",
            "Validation loss: 1.0214\n",
            "Training loss: 1.0111\n",
            "Validation loss: 1.0214\n",
            "Training loss: 1.0111\n",
            "Validation loss: 1.0214\n",
            "Training loss: 1.0111\n",
            "Validation loss: 1.0214\n",
            "Training loss: 1.0111\n",
            "Validation loss: 1.0214\n",
            "Training loss: 1.0111\n",
            "Validation loss: 1.0215\n",
            "Training loss: 1.0111\n",
            "Validation loss: 1.0215\n",
            "Training loss: 1.0111\n",
            "Validation loss: 1.0215\n",
            "Training loss: 1.0111\n",
            "Validation loss: 1.0215\n",
            "Training loss: 1.0111\n",
            "Validation loss: 1.0215\n",
            "Training loss: 1.0111\n",
            "Validation loss: 1.0215\n",
            "Training loss: 1.0111\n",
            "Validation loss: 1.0215\n",
            "Training loss: 1.0111\n",
            "Validation loss: 1.0215\n",
            "Training loss: 1.0112\n",
            "Validation loss: 1.0215\n",
            "Training loss: 1.0112\n",
            "Validation loss: 1.0215\n",
            "Training loss: 1.0112\n",
            "Validation loss: 1.0215\n",
            "Training loss: 1.0112\n",
            "Validation loss: 1.0216\n",
            "Training loss: 1.0112\n",
            "Validation loss: 1.0216\n",
            "Training loss: 1.0112\n",
            "Validation loss: 1.0216\n",
            "Training loss: 1.0112\n",
            "Validation loss: 1.0216\n",
            "Training loss: 1.0112\n",
            "Validation loss: 1.0216\n",
            "Training loss: 1.0112\n",
            "Validation loss: 1.0216\n",
            "Training loss: 1.0112\n",
            "Validation loss: 1.0216\n",
            "Training loss: 1.0112\n",
            "Validation loss: 1.0216\n",
            "Training loss: 1.0112\n",
            "Validation loss: 1.0216\n",
            "Training loss: 1.0113\n",
            "Validation loss: 1.0216\n",
            "Training loss: 1.0113\n",
            "Validation loss: 1.0216\n",
            "Training loss: 1.0113\n",
            "Validation loss: 1.0217\n",
            "Training loss: 1.0113\n",
            "Validation loss: 1.0217\n",
            "Training loss: 1.0113\n",
            "Validation loss: 1.0217\n",
            "Training loss: 1.0113\n",
            "Validation loss: 1.0217\n",
            "Training loss: 1.0113\n",
            "Validation loss: 1.0217\n",
            "Training loss: 1.0113\n",
            "Validation loss: 1.0217\n",
            "Training loss: 1.0113\n",
            "Validation loss: 1.0217\n",
            "Training loss: 1.0113\n",
            "Validation loss: 1.0217\n",
            "Training loss: 1.0113\n",
            "Validation loss: 1.0217\n",
            "Training loss: 1.0113\n",
            "Validation loss: 1.0217\n",
            "Training loss: 1.0114\n",
            "Validation loss: 1.0217\n",
            "Training loss: 1.0114\n",
            "Validation loss: 1.0218\n",
            "Training loss: 1.0114\n",
            "Validation loss: 1.0218\n",
            "Training loss: 1.0114\n",
            "Validation loss: 1.0218\n",
            "Training loss: 1.0114\n",
            "Validation loss: 1.0218\n",
            "Training loss: 1.0114\n",
            "Validation loss: 1.0218\n",
            "Training loss: 1.0114\n",
            "Validation loss: 1.0218\n",
            "Training loss: 1.0114\n",
            "Validation loss: 1.0218\n",
            "Training loss: 1.0114\n",
            "Validation loss: 1.0218\n",
            "Training loss: 1.0114\n",
            "Validation loss: 1.0218\n",
            "Training loss: 1.0114\n",
            "Validation loss: 1.0218\n",
            "Training loss: 1.0114\n",
            "Validation loss: 1.0218\n",
            "Training loss: 1.0115\n",
            "Validation loss: 1.0219\n",
            "Training loss: 1.0115\n",
            "Validation loss: 1.0219\n",
            "Training loss: 1.0115\n",
            "Validation loss: 1.0219\n",
            "Training loss: 1.0115\n",
            "Validation loss: 1.0219\n",
            "Training loss: 1.0115\n",
            "Validation loss: 1.0219\n",
            "Training loss: 1.0115\n",
            "Validation loss: 1.0219\n",
            "Training loss: 1.0115\n",
            "Validation loss: 1.0219\n",
            "Training loss: 1.0115\n",
            "Validation loss: 1.0219\n",
            "Training loss: 1.0115\n",
            "Validation loss: 1.0219\n",
            "Training loss: 1.0115\n",
            "Validation loss: 1.0219\n",
            "Training loss: 1.0115\n",
            "Validation loss: 1.0219\n",
            "Training loss: 1.0116\n",
            "Validation loss: 1.0220\n",
            "Training loss: 1.0116\n",
            "Validation loss: 1.0220\n",
            "Training loss: 1.0116\n",
            "Validation loss: 1.0220\n",
            "Training loss: 1.0116\n",
            "Validation loss: 1.0220\n",
            "Training loss: 1.0116\n",
            "Validation loss: 1.0220\n",
            "Training loss: 1.0116\n",
            "Validation loss: 1.0220\n",
            "Training loss: 1.0116\n",
            "Validation loss: 1.0220\n",
            "Training loss: 1.0116\n",
            "Validation loss: 1.0220\n",
            "Training loss: 1.0116\n",
            "Validation loss: 1.0220\n",
            "Training loss: 1.0116\n",
            "Validation loss: 1.0220\n",
            "Training loss: 1.0116\n",
            "Validation loss: 1.0220\n",
            "Training loss: 1.0116\n",
            "Validation loss: 1.0221\n",
            "Training loss: 1.0117\n",
            "Validation loss: 1.0221\n",
            "Training loss: 1.0117\n",
            "Validation loss: 1.0221\n",
            "Training loss: 1.0117\n",
            "Validation loss: 1.0221\n",
            "Training loss: 1.0117\n",
            "Validation loss: 1.0221\n",
            "Training loss: 1.0117\n",
            "Validation loss: 1.0221\n",
            "Training loss: 1.0117\n",
            "Validation loss: 1.0221\n",
            "Training loss: 1.0117\n",
            "Validation loss: 1.0221\n",
            "Training loss: 1.0117\n",
            "Validation loss: 1.0221\n",
            "Training loss: 1.0117\n",
            "Validation loss: 1.0221\n",
            "Training loss: 1.0117\n",
            "Validation loss: 1.0222\n",
            "Training loss: 1.0117\n",
            "Validation loss: 1.0222\n",
            "Training loss: 1.0118\n",
            "Validation loss: 1.0222\n",
            "Training loss: 1.0118\n",
            "Validation loss: 1.0222\n",
            "Training loss: 1.0118\n",
            "Validation loss: 1.0222\n",
            "Training loss: 1.0118\n",
            "Validation loss: 1.0222\n",
            "Training loss: 1.0118\n",
            "Validation loss: 1.0222\n",
            "Training loss: 1.0118\n",
            "Validation loss: 1.0222\n",
            "Training loss: 1.0118\n",
            "Validation loss: 1.0222\n",
            "Training loss: 1.0118\n",
            "Validation loss: 1.0222\n",
            "Training loss: 1.0118\n",
            "Validation loss: 1.0222\n",
            "Training loss: 1.0118\n",
            "Validation loss: 1.0223\n",
            "Training loss: 1.0118\n",
            "Validation loss: 1.0223\n",
            "Training loss: 1.0119\n",
            "Validation loss: 1.0223\n",
            "Training loss: 1.0119\n",
            "Validation loss: 1.0223\n",
            "Training loss: 1.0119\n",
            "Validation loss: 1.0223\n",
            "Training loss: 1.0119\n",
            "Validation loss: 1.0223\n",
            "Training loss: 1.0119\n",
            "Validation loss: 1.0223\n",
            "Training loss: 1.0119\n",
            "Validation loss: 1.0223\n",
            "Training loss: 1.0119\n",
            "Validation loss: 1.0223\n",
            "Training loss: 1.0119\n",
            "Validation loss: 1.0223\n",
            "Training loss: 1.0119\n",
            "Validation loss: 1.0224\n",
            "Training loss: 1.0119\n",
            "Validation loss: 1.0224\n",
            "Training loss: 1.0119\n",
            "Validation loss: 1.0224\n",
            "Training loss: 1.0120\n",
            "Validation loss: 1.0224\n",
            "Training loss: 1.0120\n",
            "Validation loss: 1.0224\n",
            "Training loss: 1.0120\n",
            "Validation loss: 1.0224\n",
            "Training loss: 1.0120\n",
            "Validation loss: 1.0224\n",
            "Training loss: 1.0120\n",
            "Validation loss: 1.0224\n",
            "Training loss: 1.0120\n",
            "Validation loss: 1.0224\n",
            "Training loss: 1.0120\n",
            "Validation loss: 1.0224\n",
            "Training loss: 1.0120\n",
            "Validation loss: 1.0225\n",
            "Training loss: 1.0120\n",
            "Validation loss: 1.0225\n",
            "Training loss: 1.0120\n",
            "Validation loss: 1.0225\n",
            "Training loss: 1.0120\n",
            "Validation loss: 1.0225\n",
            "Training loss: 1.0121\n",
            "Validation loss: 1.0225\n",
            "Training loss: 1.0121\n",
            "Validation loss: 1.0225\n",
            "Training loss: 1.0121\n",
            "Validation loss: 1.0225\n",
            "Training loss: 1.0121\n",
            "Validation loss: 1.0225\n",
            "Training loss: 1.0121\n",
            "Validation loss: 1.0225\n",
            "Training loss: 1.0121\n",
            "Validation loss: 1.0225\n",
            "Training loss: 1.0121\n",
            "Validation loss: 1.0226\n",
            "Training loss: 1.0121\n",
            "Validation loss: 1.0226\n",
            "Training loss: 1.0121\n",
            "Validation loss: 1.0226\n",
            "Training loss: 1.0121\n",
            "Validation loss: 1.0226\n",
            "Training loss: 1.0121\n",
            "Validation loss: 1.0226\n",
            "Training loss: 1.0122\n",
            "Validation loss: 1.0226\n",
            "Training loss: 1.0122\n",
            "Validation loss: 1.0226\n",
            "Training loss: 1.0122\n",
            "Validation loss: 1.0226\n",
            "Training loss: 1.0122\n",
            "Validation loss: 1.0226\n",
            "Training loss: 1.0122\n",
            "Validation loss: 1.0226\n",
            "Training loss: 1.0122\n",
            "Validation loss: 1.0227\n",
            "Training loss: 1.0122\n",
            "Validation loss: 1.0227\n",
            "Training loss: 1.0122\n",
            "Validation loss: 1.0227\n",
            "Training loss: 1.0122\n",
            "Validation loss: 1.0227\n",
            "Training loss: 1.0122\n",
            "Validation loss: 1.0227\n",
            "Training loss: 1.0123\n",
            "Validation loss: 1.0227\n",
            "Training loss: 1.0123\n",
            "Validation loss: 1.0227\n",
            "Training loss: 1.0123\n",
            "Validation loss: 1.0227\n",
            "Training loss: 1.0123\n",
            "Validation loss: 1.0227\n",
            "Training loss: 1.0123\n",
            "Validation loss: 1.0227\n",
            "Training loss: 1.0123\n",
            "Validation loss: 1.0228\n",
            "Training loss: 1.0123\n",
            "Validation loss: 1.0228\n",
            "Training loss: 1.0123\n",
            "Validation loss: 1.0228\n",
            "Training loss: 1.0123\n",
            "Validation loss: 1.0228\n",
            "Training loss: 1.0123\n",
            "Validation loss: 1.0228\n",
            "Training loss: 1.0123\n",
            "Validation loss: 1.0228\n",
            "Training loss: 1.0124\n",
            "Validation loss: 1.0228\n",
            "Training loss: 1.0124\n",
            "Validation loss: 1.0228\n",
            "Training loss: 1.0124\n",
            "Validation loss: 1.0228\n",
            "Training loss: 1.0124\n",
            "Validation loss: 1.0228\n",
            "Training loss: 1.0124\n",
            "Validation loss: 1.0229\n",
            "Training loss: 1.0124\n",
            "Validation loss: 1.0229\n",
            "Training loss: 1.0124\n",
            "Validation loss: 1.0229\n",
            "Training loss: 1.0124\n",
            "Validation loss: 1.0229\n",
            "Training loss: 1.0124\n",
            "Validation loss: 1.0229\n",
            "Training loss: 1.0124\n",
            "Validation loss: 1.0229\n",
            "Training loss: 1.0125\n",
            "Validation loss: 1.0229\n",
            "Training loss: 1.0125\n",
            "Validation loss: 1.0229\n",
            "Training loss: 1.0125\n",
            "Validation loss: 1.0229\n",
            "Training loss: 1.0125\n",
            "Validation loss: 1.0229\n",
            "Training loss: 1.0125\n",
            "Validation loss: 1.0230\n",
            "Training loss: 1.0125\n",
            "Validation loss: 1.0230\n",
            "Training loss: 1.0125\n",
            "Validation loss: 1.0230\n",
            "Training loss: 1.0125\n",
            "Validation loss: 1.0230\n",
            "Training loss: 1.0125\n",
            "Validation loss: 1.0230\n",
            "Training loss: 1.0125\n",
            "Validation loss: 1.0230\n",
            "Training loss: 1.0125\n",
            "Validation loss: 1.0230\n",
            "Training loss: 1.0126\n",
            "Validation loss: 1.0230\n",
            "Training loss: 1.0126\n",
            "Validation loss: 1.0230\n",
            "Training loss: 1.0126\n",
            "Validation loss: 1.0230\n",
            "Training loss: 1.0126\n",
            "Validation loss: 1.0231\n",
            "Training loss: 1.0126\n",
            "Validation loss: 1.0231\n",
            "Training loss: 1.0126\n",
            "Validation loss: 1.0231\n",
            "Training loss: 1.0126\n",
            "Validation loss: 1.0231\n",
            "Training loss: 1.0126\n",
            "Validation loss: 1.0231\n",
            "Training loss: 1.0126\n",
            "Validation loss: 1.0231\n",
            "Training loss: 1.0126\n",
            "Validation loss: 1.0231\n",
            "Training loss: 1.0127\n",
            "Validation loss: 1.0231\n",
            "Training loss: 1.0127\n",
            "Validation loss: 1.0231\n",
            "Training loss: 1.0127\n",
            "Validation loss: 1.0232\n",
            "Training loss: 1.0127\n",
            "Validation loss: 1.0232\n",
            "Training loss: 1.0127\n",
            "Validation loss: 1.0232\n",
            "Training loss: 1.0127\n",
            "Validation loss: 1.0232\n",
            "Training loss: 1.0127\n",
            "Validation loss: 1.0232\n",
            "Training loss: 1.0127\n",
            "Validation loss: 1.0232\n",
            "Training loss: 1.0127\n",
            "Validation loss: 1.0232\n",
            "Training loss: 1.0127\n",
            "Validation loss: 1.0232\n",
            "Training loss: 1.0128\n",
            "Validation loss: 1.0232\n",
            "Training loss: 1.0128\n",
            "Validation loss: 1.0232\n",
            "Training loss: 1.0128\n",
            "Validation loss: 1.0233\n",
            "Training loss: 1.0128\n",
            "Validation loss: 1.0233\n",
            "Training loss: 1.0128\n",
            "Validation loss: 1.0233\n",
            "Training loss: 1.0128\n",
            "Validation loss: 1.0233\n",
            "Training loss: 1.0128\n",
            "Validation loss: 1.0233\n",
            "Training loss: 1.0128\n",
            "Validation loss: 1.0233\n",
            "Training loss: 1.0128\n",
            "Validation loss: 1.0233\n",
            "Training loss: 1.0128\n",
            "Validation loss: 1.0233\n",
            "Training loss: 1.0129\n",
            "Validation loss: 1.0233\n",
            "Training loss: 1.0129\n",
            "Validation loss: 1.0234\n",
            "Training loss: 1.0129\n",
            "Validation loss: 1.0234\n",
            "Training loss: 1.0129\n",
            "Validation loss: 1.0234\n",
            "Training loss: 1.0129\n",
            "Validation loss: 1.0234\n",
            "Training loss: 1.0129\n",
            "Validation loss: 1.0234\n",
            "Training loss: 1.0129\n",
            "Validation loss: 1.0234\n",
            "Training loss: 1.0129\n",
            "Validation loss: 1.0234\n",
            "Training loss: 1.0129\n",
            "Validation loss: 1.0234\n",
            "Training loss: 1.0129\n",
            "Validation loss: 1.0234\n",
            "Training loss: 1.0130\n",
            "Validation loss: 1.0235\n",
            "Training loss: 1.0130\n",
            "Validation loss: 1.0235\n",
            "Training loss: 1.0130\n",
            "Validation loss: 1.0235\n",
            "Training loss: 1.0130\n",
            "Validation loss: 1.0235\n",
            "Training loss: 1.0130\n",
            "Validation loss: 1.0235\n",
            "Training loss: 1.0130\n",
            "Validation loss: 1.0235\n",
            "Training loss: 1.0130\n",
            "Validation loss: 1.0235\n",
            "Training loss: 1.0130\n",
            "Validation loss: 1.0235\n",
            "Training loss: 1.0130\n",
            "Validation loss: 1.0235\n",
            "Training loss: 1.0130\n",
            "Validation loss: 1.0236\n",
            "Training loss: 1.0131\n",
            "Validation loss: 1.0236\n",
            "Training loss: 1.0131\n",
            "Validation loss: 1.0236\n",
            "Training loss: 1.0131\n",
            "Validation loss: 1.0236\n",
            "Training loss: 1.0131\n",
            "Validation loss: 1.0236\n",
            "Training loss: 1.0131\n",
            "Validation loss: 1.0236\n",
            "Training loss: 1.0131\n",
            "Validation loss: 1.0236\n",
            "Training loss: 1.0131\n",
            "Validation loss: 1.0236\n",
            "Training loss: 1.0131\n",
            "Validation loss: 1.0236\n",
            "Training loss: 1.0131\n",
            "Validation loss: 1.0237\n",
            "Training loss: 1.0132\n",
            "Validation loss: 1.0237\n",
            "Training loss: 1.0132\n",
            "Validation loss: 1.0237\n",
            "Training loss: 1.0132\n",
            "Validation loss: 1.0237\n",
            "Training loss: 1.0132\n",
            "Validation loss: 1.0237\n",
            "Training loss: 1.0132\n",
            "Validation loss: 1.0237\n",
            "Training loss: 1.0132\n",
            "Validation loss: 1.0237\n",
            "Training loss: 1.0132\n",
            "Validation loss: 1.0237\n",
            "Training loss: 1.0132\n",
            "Validation loss: 1.0237\n",
            "Training loss: 1.0132\n",
            "Validation loss: 1.0238\n",
            "Training loss: 1.0132\n",
            "Validation loss: 1.0238\n",
            "Training loss: 1.0133\n",
            "Validation loss: 1.0238\n",
            "Training loss: 1.0133\n",
            "Validation loss: 1.0238\n",
            "Training loss: 1.0133\n",
            "Validation loss: 1.0238\n",
            "Training loss: 1.0133\n",
            "Validation loss: 1.0238\n",
            "Training loss: 1.0133\n",
            "Validation loss: 1.0238\n",
            "Training loss: 1.0133\n",
            "Validation loss: 1.0238\n",
            "Training loss: 1.0133\n",
            "Validation loss: 1.0238\n",
            "Training loss: 1.0133\n",
            "Validation loss: 1.0239\n",
            "Training loss: 1.0133\n",
            "Validation loss: 1.0239\n",
            "Training loss: 1.0134\n",
            "Validation loss: 1.0239\n",
            "Training loss: 1.0134\n",
            "Validation loss: 1.0239\n",
            "Training loss: 1.0134\n",
            "Validation loss: 1.0239\n",
            "Training loss: 1.0134\n",
            "Validation loss: 1.0239\n",
            "Training loss: 1.0134\n",
            "Validation loss: 1.0239\n",
            "Training loss: 1.0134\n",
            "Validation loss: 1.0239\n",
            "Training loss: 1.0134\n",
            "Validation loss: 1.0239\n",
            "Training loss: 1.0134\n",
            "Validation loss: 1.0240\n",
            "Training loss: 1.0134\n",
            "Validation loss: 1.0240\n",
            "Training loss: 1.0134\n",
            "Validation loss: 1.0240\n",
            "Training loss: 1.0135\n",
            "Validation loss: 1.0240\n",
            "Training loss: 1.0135\n",
            "Validation loss: 1.0240\n",
            "Training loss: 1.0135\n",
            "Validation loss: 1.0240\n",
            "Training loss: 1.0135\n",
            "Validation loss: 1.0240\n",
            "Training loss: 1.0135\n",
            "Validation loss: 1.0240\n",
            "Training loss: 1.0135\n",
            "Validation loss: 1.0240\n",
            "Training loss: 1.0135\n",
            "Validation loss: 1.0241\n",
            "Training loss: 1.0135\n",
            "Validation loss: 1.0241\n",
            "Training loss: 1.0135\n",
            "Validation loss: 1.0241\n",
            "Training loss: 1.0136\n",
            "Validation loss: 1.0241\n",
            "Training loss: 1.0136\n",
            "Validation loss: 1.0241\n",
            "Training loss: 1.0136\n",
            "Validation loss: 1.0241\n",
            "Training loss: 1.0136\n",
            "Validation loss: 1.0241\n",
            "Training loss: 1.0136\n",
            "Validation loss: 1.0241\n",
            "Training loss: 1.0136\n",
            "Validation loss: 1.0241\n",
            "Training loss: 1.0136\n",
            "Validation loss: 1.0242\n",
            "Training loss: 1.0136\n",
            "Validation loss: 1.0242\n",
            "Training loss: 1.0136\n",
            "Validation loss: 1.0242\n",
            "Training loss: 1.0137\n",
            "Validation loss: 1.0242\n",
            "Training loss: 1.0137\n",
            "Validation loss: 1.0242\n",
            "Training loss: 1.0137\n",
            "Validation loss: 1.0242\n",
            "Training loss: 1.0137\n",
            "Validation loss: 1.0242\n",
            "Training loss: 1.0137\n",
            "Validation loss: 1.0242\n",
            "Training loss: 1.0137\n",
            "Validation loss: 1.0243\n",
            "Training loss: 1.0137\n",
            "Validation loss: 1.0243\n",
            "Training loss: 1.0137\n",
            "Validation loss: 1.0243\n",
            "Training loss: 1.0137\n",
            "Validation loss: 1.0243\n",
            "Training loss: 1.0138\n",
            "Validation loss: 1.0243\n",
            "Training loss: 1.0138\n",
            "Validation loss: 1.0243\n",
            "Training loss: 1.0138\n",
            "Validation loss: 1.0243\n",
            "Training loss: 1.0138\n",
            "Validation loss: 1.0243\n",
            "Training loss: 1.0138\n",
            "Validation loss: 1.0243\n",
            "Training loss: 1.0138\n",
            "Validation loss: 1.0244\n",
            "Training loss: 1.0138\n",
            "Validation loss: 1.0244\n",
            "Training loss: 1.0138\n",
            "Validation loss: 1.0244\n",
            "Training loss: 1.0138\n",
            "Validation loss: 1.0244\n",
            "Training loss: 1.0138\n",
            "Validation loss: 1.0244\n",
            "Training loss: 1.0139\n",
            "Validation loss: 1.0244\n",
            "Training loss: 1.0139\n",
            "Validation loss: 1.0244\n",
            "Training loss: 1.0139\n",
            "Validation loss: 1.0244\n",
            "Training loss: 1.0139\n",
            "Validation loss: 1.0245\n",
            "Training loss: 1.0139\n",
            "Validation loss: 1.0245\n",
            "Training loss: 1.0139\n",
            "Validation loss: 1.0245\n",
            "Training loss: 1.0139\n",
            "Validation loss: 1.0245\n",
            "Training loss: 1.0139\n",
            "Validation loss: 1.0245\n",
            "Training loss: 1.0140\n",
            "Validation loss: 1.0245\n",
            "Training loss: 1.0140\n",
            "Validation loss: 1.0245\n",
            "Training loss: 1.0140\n",
            "Validation loss: 1.0245\n",
            "Training loss: 1.0140\n",
            "Validation loss: 1.0245\n",
            "Training loss: 1.0140\n",
            "Validation loss: 1.0246\n",
            "Training loss: 1.0140\n",
            "Validation loss: 1.0246\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfMFzzEEIoPa",
        "colab_type": "code",
        "outputId": "12a07aeb-16a6-4c12-ea30-7fb37a0d5bb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(train_features.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(13903, 56)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89uuYTFCIoOA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "563bfd68-d682-4c5d-873b-53716f432dcf"
      },
      "source": [
        "plt.plot(losses['train'], label='Training loss')\n",
        "plt.plot(losses['validation'], label='Validation loss')\n",
        "plt.legend()"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f46902a19b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WulEdN5NIoM9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJ1O7lxgIoL8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Su9c_F2gIoKb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DHfVgV8IoHZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}